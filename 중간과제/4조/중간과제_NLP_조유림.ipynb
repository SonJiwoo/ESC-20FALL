{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iJAybNcn_S9C"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pj_P7en9ZQw"
      },
      "source": [
        "# Natural Language Processing Assignment: Spam Filter\n",
        "## Import necessary libs and datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EziGgWLOdu_b"
      },
      "source": [
        "#### 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoN1L0zOcd6H"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "import urllib.request"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEzpUVgH9VeV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\", filename=\"spam.csv\")\n",
        "data = pd.read_csv('spam.csv', encoding='latin1')\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o41ve7N99Yww",
        "outputId": "d866546d-4823-4af4-9263-2c104c4a19cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#spam이 1\n",
        "del data['Unnamed: 2']\n",
        "del data['Unnamed: 3']\n",
        "del data['Unnamed: 4']\n",
        "\n",
        "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n",
        "data['text'] = data['v2']\n",
        "data['isSpam'] = data['v1']\n",
        "\n",
        "del data['v1'], data['v2']\n",
        "\n",
        "print(f'Data Shape: {data.shape}')\n",
        "# imbalanced data\n",
        "print(data['isSpam'].value_counts())"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (5572, 2)\n",
            "0    4825\n",
            "1     747\n",
            "Name: isSpam, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9ftc8WM9jms"
      },
      "source": [
        "### 전처리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74S0S3y5dS8c"
      },
      "source": [
        "#### 특수기호, 영어 아닌 문자, 이중 space 제거, 대문자 소문자로 전환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5cFLugt9Yzg"
      },
      "source": [
        "import re\n",
        "\n",
        "pattern1 = '[^\\w\\s]' #특수기호 제거\n",
        "pattern2 = re.compile(r'\\s+') #이중 space 제거\n",
        "pattern3 = re.compile('[^a-zA-Z]') #영어가 아닌 문자 공백으로 대체 \n",
        "\n",
        "def preprocess(content)   :\n",
        "    content = re.sub(pattern1, ' ', content)\n",
        "    content = re.sub(pattern3, ' ', content)\n",
        "    content = re.sub(pattern2, ' ', content)\n",
        "    content = content.lower() #대문자 소문자로 전환\n",
        "        \n",
        "    return content"
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bZN_7SU9Y20"
      },
      "source": [
        "data['text_n'] = data['text'].apply(lambda x: preprocess(x))"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcL-sSo79ujt"
      },
      "source": [
        "#### 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piQ9Zfuh-qDO",
        "outputId": "2d168989-3e37-4250-aaff-c9c87a8ba515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrurKrOE9Y54",
        "outputId": "3e96422e-516b-4298-f679-4fe8675d8d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# is that a the 등 불용어 제거\n",
        "from nltk.corpus import stopwords  \n",
        "stopwords.words('english')[:10]  "
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOcVxXWY9Y8h"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def stop_word_remove(content):\n",
        "    token = word_tokenize(content)\n",
        "    result = []\n",
        "    for w in token:\n",
        "        if w not in stop_words:\n",
        "            result.append(w)\n",
        "    text = ' '.join(result)\n",
        "    return text"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUhuWtwX9Y_U"
      },
      "source": [
        "data['text_n'] = data['text_n'].apply(lambda x: stop_word_remove(x))"
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE5ElOYz98zi"
      },
      "source": [
        "#### glove pre-trained word vector 가져오기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1TrCZ4r6UmU"
      },
      "source": [
        "import numpy as np\n",
        "import gensim"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbIJnOd27aVU",
        "outputId": "deba41ac-72bf-4066-8b71-96cb08eb6664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/esc"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/esc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dDI-hOFlPwB"
      },
      "source": [
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)  "
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJUNDTwT7iFD",
        "outputId": "3a97d79d-5468-42b1-f776-a8647398a580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(word2vec_model.vectors.shape)"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfvGu5cr86Oz",
        "outputId": "0e55e256-d718-4120-a5f6-cff3a5c638b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "'''\n",
        "import os\n",
        "embedding_dict = dict()\n",
        "f = open(os.path.join('glove.6B.100d.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32') # 100개의 값을 가지는 array로 변환\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "\n",
        "print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))\n",
        "'''"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimport os\\nembedding_dict = dict()\\nf = open(os.path.join('glove.6B.100d.txt'), encoding='utf-8')\\nfor line in f:\\n    word_vector = line.split()\\n    word = word_vector[0]\\n    word_vector_arr = np.asarray(word_vector[1:], dtype='float32') # 100개의 값을 가지는 array로 변환\\n    embedding_dict[word] = word_vector_arr\\nf.close()\\n\\nprint('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyt_y6xd-9HO",
        "outputId": "827e2b84-bea2-4f78-bb4b-fdd612a03dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print(len(embedding_dict['respectable']))\n",
        "#임베딩 된 벡터의 차원은 100차원 "
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
            "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
            "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
            "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
            " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
            " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
            " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
            " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
            " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
            " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
            " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
            "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
            "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
            "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
            " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
            " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
            " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXTGWadsi_sH"
      },
      "source": [
        "#### pre-trained vector에 없는 단어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoMPKerxjSRr"
      },
      "source": [
        "#우리가 토큰화 한 단어 들 중 glove에서 학습된 단어 벡터가 무엇인지 알아보자\n",
        "word_in_glove = []\n",
        "unknown = []\n",
        "for word in unique_word_list:\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        word_in_glove.append(word)\n",
        "    if embedding_vector is None:\n",
        "        unknown.append(word)"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWDeSqV_jUCY",
        "outputId": "a26b71f2-c359-46d4-d6c8-c96e955531e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(word_in_glove)"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th2a3P38m8WX",
        "outputId": "31e8e312-3a3a-4f3d-d3f9-358122a3fe5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "word_in_glove"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go',\n",
              " 'jurong',\n",
              " 'point',\n",
              " 'crazy',\n",
              " 'available',\n",
              " 'bugis',\n",
              " 'great',\n",
              " 'world',\n",
              " 'la',\n",
              " 'buffet',\n",
              " 'cine',\n",
              " 'got',\n",
              " 'amore',\n",
              " 'wat',\n",
              " 'ok',\n",
              " 'lar',\n",
              " 'joking',\n",
              " 'wif',\n",
              " 'oni',\n",
              " 'free',\n",
              " 'entry',\n",
              " 'comp',\n",
              " 'win',\n",
              " 'fa',\n",
              " 'cup',\n",
              " 'final',\n",
              " 'tkts',\n",
              " 'st',\n",
              " 'may',\n",
              " 'text',\n",
              " 'receive',\n",
              " 'question',\n",
              " 'std',\n",
              " 'txt',\n",
              " 'rate',\n",
              " 'apply',\n",
              " 'dun',\n",
              " 'say',\n",
              " 'early',\n",
              " 'hor',\n",
              " 'already',\n",
              " 'nah',\n",
              " 'think',\n",
              " 'goes',\n",
              " 'usf',\n",
              " 'lives',\n",
              " 'around',\n",
              " 'though',\n",
              " 'hey',\n",
              " 'darling',\n",
              " 'week',\n",
              " 'word',\n",
              " 'back',\n",
              " 'like',\n",
              " 'fun',\n",
              " 'still',\n",
              " 'tb',\n",
              " 'xxx',\n",
              " 'send',\n",
              " 'rcv',\n",
              " 'even',\n",
              " 'brother',\n",
              " 'speak',\n",
              " 'treat',\n",
              " 'aids',\n",
              " 'patent',\n",
              " 'per',\n",
              " 'request',\n",
              " 'melle',\n",
              " 'oru',\n",
              " 'set',\n",
              " 'callers',\n",
              " 'press',\n",
              " 'copy',\n",
              " 'friends',\n",
              " 'winner',\n",
              " 'valued',\n",
              " 'network',\n",
              " 'customer',\n",
              " 'selected',\n",
              " 'prize',\n",
              " 'reward',\n",
              " 'claim',\n",
              " 'call',\n",
              " 'code',\n",
              " 'kl',\n",
              " 'valid',\n",
              " 'hours',\n",
              " 'mobile',\n",
              " 'months',\n",
              " 'entitled',\n",
              " 'update',\n",
              " 'latest',\n",
              " 'colour',\n",
              " 'mobiles',\n",
              " 'camera',\n",
              " 'co',\n",
              " 'gon',\n",
              " 'na',\n",
              " 'home',\n",
              " 'soon',\n",
              " 'want',\n",
              " 'talk',\n",
              " 'stuff',\n",
              " 'anymore',\n",
              " 'tonight',\n",
              " 'cried',\n",
              " 'enough',\n",
              " 'today',\n",
              " 'six',\n",
              " 'chances',\n",
              " 'cash',\n",
              " 'pounds',\n",
              " 'csh',\n",
              " 'cost',\n",
              " 'day',\n",
              " 'days',\n",
              " 'reply',\n",
              " 'hl',\n",
              " 'info',\n",
              " 'urgent',\n",
              " 'membership',\n",
              " 'jackpot',\n",
              " 'www',\n",
              " 'net',\n",
              " 'rw',\n",
              " 'searching',\n",
              " 'right',\n",
              " 'words',\n",
              " 'thank',\n",
              " 'breather',\n",
              " 'promise',\n",
              " 'wont',\n",
              " 'take',\n",
              " 'help',\n",
              " 'granted',\n",
              " 'fulfil',\n",
              " 'wonderful',\n",
              " 'blessing',\n",
              " 'times',\n",
              " 'date',\n",
              " 'sunday',\n",
              " 'use',\n",
              " 'credit',\n",
              " 'click',\n",
              " 'wap',\n",
              " 'link',\n",
              " 'next',\n",
              " 'message',\n",
              " 'http',\n",
              " 'com',\n",
              " 'oh',\n",
              " 'watching',\n",
              " 'eh',\n",
              " 'remember',\n",
              " 'spell',\n",
              " 'name',\n",
              " 'yes',\n",
              " 'naughty',\n",
              " 'make',\n",
              " 'wet',\n",
              " 'fine',\n",
              " 'way',\n",
              " 'feel',\n",
              " 'gota',\n",
              " 'england',\n",
              " 'macedonia',\n",
              " 'dont',\n",
              " 'miss',\n",
              " 'goals',\n",
              " 'team',\n",
              " 'news',\n",
              " 'ur',\n",
              " 'national',\n",
              " 'eg',\n",
              " 'try',\n",
              " 'wales',\n",
              " 'scotland',\n",
              " 'seriously',\n",
              " 'going',\n",
              " 'ha',\n",
              " 'pay',\n",
              " 'first',\n",
              " 'da',\n",
              " 'stock',\n",
              " 'comin',\n",
              " 'aft',\n",
              " 'finish',\n",
              " 'lunch',\n",
              " 'str',\n",
              " 'lor',\n",
              " 'ard',\n",
              " 'smth',\n",
              " 'alright',\n",
              " 'meet',\n",
              " 'sooner',\n",
              " 'forced',\n",
              " 'eat',\n",
              " 'slice',\n",
              " 'really',\n",
              " 'hungry',\n",
              " 'tho',\n",
              " 'sucks',\n",
              " 'mark',\n",
              " 'getting',\n",
              " 'worried',\n",
              " 'knows',\n",
              " 'sick',\n",
              " 'turn',\n",
              " 'pizza',\n",
              " 'lol',\n",
              " 'always',\n",
              " 'convincing',\n",
              " 'catch',\n",
              " 'bus',\n",
              " 'frying',\n",
              " 'egg',\n",
              " 'tea',\n",
              " 'eating',\n",
              " 'mom',\n",
              " 'left',\n",
              " 'dinner',\n",
              " 'love',\n",
              " 'amp',\n",
              " 'packing',\n",
              " 'car',\n",
              " 'let',\n",
              " 'know',\n",
              " 'room',\n",
              " 'ahhh',\n",
              " 'work',\n",
              " 'vaguely',\n",
              " 'wait',\n",
              " 'clear',\n",
              " 'sure',\n",
              " 'sarcastic',\n",
              " 'live',\n",
              " 'us',\n",
              " 'yeah',\n",
              " 'apologetic',\n",
              " 'fallen',\n",
              " 'actin',\n",
              " 'spoilt',\n",
              " 'child',\n",
              " 'caught',\n",
              " 'till',\n",
              " 'badly',\n",
              " 'cheers',\n",
              " 'tell',\n",
              " 'anything',\n",
              " 'fear',\n",
              " 'fainting',\n",
              " 'housework',\n",
              " 'quick',\n",
              " 'cuppa',\n",
              " 'thanks',\n",
              " 'subscription',\n",
              " 'ringtone',\n",
              " 'uk',\n",
              " 'charged',\n",
              " 'month',\n",
              " 'please',\n",
              " 'confirm',\n",
              " 'replying',\n",
              " 'yup',\n",
              " 'look',\n",
              " 'timings',\n",
              " 'msg',\n",
              " 'xuhui',\n",
              " 'learn',\n",
              " 'nd',\n",
              " 'lesson',\n",
              " 'oops',\n",
              " 'roommate',\n",
              " 'done',\n",
              " 'see',\n",
              " 'letter',\n",
              " 'decide',\n",
              " 'hello',\n",
              " 'saturday',\n",
              " 'texting',\n",
              " 'decided',\n",
              " 'tomo',\n",
              " 'trying',\n",
              " 'invite',\n",
              " 'pls',\n",
              " 'ahead',\n",
              " 'watts',\n",
              " 'wanted',\n",
              " 'weekend',\n",
              " 'abiola',\n",
              " 'forget',\n",
              " 'need',\n",
              " 'crave',\n",
              " 'sweet',\n",
              " 'arabian',\n",
              " 'steed',\n",
              " 'yummy',\n",
              " 'rodger',\n",
              " 'burns',\n",
              " 'tried',\n",
              " 'sms',\n",
              " 'nokia',\n",
              " 'camcorder',\n",
              " 'delivery',\n",
              " 'tomorrow',\n",
              " 'seeing',\n",
              " 'hope',\n",
              " 'man',\n",
              " 'well',\n",
              " 'endowed',\n",
              " 'lt',\n",
              " 'gt',\n",
              " 'inches',\n",
              " 'calls',\n",
              " 'messages',\n",
              " 'missed',\n",
              " 'get',\n",
              " 'hep',\n",
              " 'immunisation',\n",
              " 'nigeria',\n",
              " 'fair',\n",
              " 'hopefully',\n",
              " 'tyler',\n",
              " 'could',\n",
              " 'maybe',\n",
              " 'ask',\n",
              " 'bit',\n",
              " 'stubborn',\n",
              " 'hospital',\n",
              " 'kept',\n",
              " 'telling',\n",
              " 'weak',\n",
              " 'sucker',\n",
              " 'hospitals',\n",
              " 'suckers',\n",
              " 'time',\n",
              " 'saw',\n",
              " 'class',\n",
              " 'gram',\n",
              " 'usually',\n",
              " 'runs',\n",
              " 'half',\n",
              " 'eighth',\n",
              " 'smarter',\n",
              " 'gets',\n",
              " 'almost',\n",
              " 'whole',\n",
              " 'second',\n",
              " 'fyi',\n",
              " 'ride',\n",
              " 'morning',\n",
              " 'crashing',\n",
              " 'place',\n",
              " 'wow',\n",
              " 'never',\n",
              " 'realized',\n",
              " 'embarassed',\n",
              " 'accomodations',\n",
              " 'thought',\n",
              " 'liked',\n",
              " 'since',\n",
              " 'best',\n",
              " 'seemed',\n",
              " 'happy',\n",
              " 'cave',\n",
              " 'sorry',\n",
              " 'give',\n",
              " 'offered',\n",
              " 'embarassing',\n",
              " 'ac',\n",
              " 'new',\n",
              " 'jersey',\n",
              " 'devils',\n",
              " 'detroit',\n",
              " 'red',\n",
              " 'wings',\n",
              " 'play',\n",
              " 'ice',\n",
              " 'hockey',\n",
              " 'correct',\n",
              " 'incorrect',\n",
              " 'end',\n",
              " 'mallika',\n",
              " 'sherawat',\n",
              " 'yesterday',\n",
              " 'find',\n",
              " 'url',\n",
              " 'congrats',\n",
              " 'year',\n",
              " 'special',\n",
              " 'cinema',\n",
              " 'pass',\n",
              " 'matrix',\n",
              " 'starwars',\n",
              " 'etc',\n",
              " 'bx',\n",
              " 'ip',\n",
              " 'pm',\n",
              " 'later',\n",
              " 'meeting',\n",
              " 'reached',\n",
              " 'sehwag',\n",
              " 'odi',\n",
              " 'series',\n",
              " 'pick',\n",
              " 'burger',\n",
              " 'move',\n",
              " 'pain',\n",
              " 'killing',\n",
              " 'good',\n",
              " 'joke',\n",
              " 'girls',\n",
              " 'situation',\n",
              " 'seekers',\n",
              " 'part',\n",
              " 'checking',\n",
              " 'iq',\n",
              " 'roommates',\n",
              " 'took',\n",
              " 'forever',\n",
              " 'come',\n",
              " 'double',\n",
              " 'check',\n",
              " 'hair',\n",
              " 'dresser',\n",
              " 'said',\n",
              " 'wun',\n",
              " 'cut',\n",
              " 'short',\n",
              " 'nice',\n",
              " 'pleased',\n",
              " 'advise',\n",
              " 'following',\n",
              " 'recent',\n",
              " 'review',\n",
              " 'mob',\n",
              " 'awarded',\n",
              " 'bonus',\n",
              " 'song',\n",
              " 'dedicated',\n",
              " 'dedicate',\n",
              " 'valuable',\n",
              " 'complimentary',\n",
              " 'trip',\n",
              " 'trav',\n",
              " 'aco',\n",
              " 'dis',\n",
              " 'ls',\n",
              " 'aj',\n",
              " 'hear',\n",
              " 'divorce',\n",
              " 'barbie',\n",
              " 'comes',\n",
              " 'ken',\n",
              " 'plane',\n",
              " 'wah',\n",
              " 'lucky',\n",
              " 'save',\n",
              " 'money',\n",
              " 'hee',\n",
              " 'finished',\n",
              " 'hi',\n",
              " 'babe',\n",
              " 'im',\n",
              " 'wan',\n",
              " 'something',\n",
              " 'xx',\n",
              " 'performed',\n",
              " 'waiting',\n",
              " 'machan',\n",
              " 'thats',\n",
              " 'cool',\n",
              " 'gentleman',\n",
              " 'dignity',\n",
              " 'respect',\n",
              " 'peoples',\n",
              " 'much',\n",
              " 'shy',\n",
              " 'pa',\n",
              " 'operate',\n",
              " 'looking',\n",
              " 'job',\n",
              " 'ta',\n",
              " 'earn',\n",
              " 'ah',\n",
              " 'stop',\n",
              " 'real',\n",
              " 'yo',\n",
              " 'tickets',\n",
              " 'one',\n",
              " 'jacket',\n",
              " 'used',\n",
              " 'multis',\n",
              " 'started',\n",
              " 'requests',\n",
              " 'came',\n",
              " 'bed',\n",
              " 'coins',\n",
              " 'factory',\n",
              " 'ela',\n",
              " 'kano',\n",
              " 'il',\n",
              " 'download',\n",
              " 'wen',\n",
              " 'stand',\n",
              " 'close',\n",
              " 'another',\n",
              " 'night',\n",
              " 'spent',\n",
              " 'late',\n",
              " 'afternoon',\n",
              " 'casualty',\n",
              " 'means',\n",
              " 'moro',\n",
              " 'includes',\n",
              " 'sheets',\n",
              " 'smile',\n",
              " 'pleasure',\n",
              " 'trouble',\n",
              " 'pours',\n",
              " 'rain',\n",
              " 'sum',\n",
              " 'hurts',\n",
              " 'someone',\n",
              " 'loves',\n",
              " 'smiling',\n",
              " 'service',\n",
              " 'representative',\n",
              " 'guaranteed',\n",
              " 'havent',\n",
              " 'planning',\n",
              " 'buy',\n",
              " 'lido',\n",
              " 'show',\n",
              " 'collected',\n",
              " 'simply',\n",
              " 'password',\n",
              " 'mix',\n",
              " 'verify',\n",
              " 'usher',\n",
              " 'britney',\n",
              " 'fml',\n",
              " 'telugu',\n",
              " 'movie',\n",
              " 'abt',\n",
              " 'loads',\n",
              " 'loans',\n",
              " 'wk',\n",
              " 'run',\n",
              " 'forgot',\n",
              " 'hairdressers',\n",
              " 'appointment',\n",
              " 'four',\n",
              " 'shower',\n",
              " 'beforehand',\n",
              " 'cause',\n",
              " 'prob',\n",
              " 'ham',\n",
              " 'nothing',\n",
              " 'else',\n",
              " 'okay',\n",
              " 'price',\n",
              " 'long',\n",
              " 'legal',\n",
              " 'ave',\n",
              " 'ams',\n",
              " 'gone',\n",
              " 'driving',\n",
              " 'test',\n",
              " 'yet',\n",
              " 'mean',\n",
              " 'guess',\n",
              " 'gave',\n",
              " 'boston',\n",
              " 'men',\n",
              " 'changed',\n",
              " 'search',\n",
              " 'location',\n",
              " 'nyc',\n",
              " 'cuz',\n",
              " 'page',\n",
              " 'says',\n",
              " 'umma',\n",
              " 'life',\n",
              " 'vava',\n",
              " 'lot',\n",
              " 'dear',\n",
              " 'wishes',\n",
              " 'birthday',\n",
              " 'making',\n",
              " 'truly',\n",
              " 'memorable',\n",
              " 'hit',\n",
              " 'would',\n",
              " 'address',\n",
              " 'considering',\n",
              " 'computer',\n",
              " 'minecraft',\n",
              " 'server',\n",
              " 'grumpy',\n",
              " 'old',\n",
              " 'people',\n",
              " 'better',\n",
              " 'lying',\n",
              " 'jokes',\n",
              " 'worry',\n",
              " 'busy',\n",
              " 'plural',\n",
              " 'noun',\n",
              " 'research',\n",
              " 'cos',\n",
              " 'things',\n",
              " 'scared',\n",
              " 'mah',\n",
              " 'loud',\n",
              " 'gent',\n",
              " 'contact',\n",
              " 'last',\n",
              " 'weekends',\n",
              " 'draw',\n",
              " 'shows',\n",
              " 'hrs',\n",
              " 'ppm',\n",
              " 'wa',\n",
              " 'sentence',\n",
              " 'formal',\n",
              " 'anyway',\n",
              " 'juz',\n",
              " 'tt',\n",
              " 'eatin',\n",
              " 'puttin',\n",
              " 'weight',\n",
              " 'haha',\n",
              " 'happened',\n",
              " 'entered',\n",
              " 'cabin',\n",
              " 'boss',\n",
              " 'felt',\n",
              " 'invited',\n",
              " 'apartment',\n",
              " 'went',\n",
              " 'specially',\n",
              " 'holiday',\n",
              " 'flights',\n",
              " 'inc',\n",
              " 'operator',\n",
              " 'min',\n",
              " 'must',\n",
              " 'friday',\n",
              " 'potato',\n",
              " 'ratio',\n",
              " 'tortilla',\n",
              " 'needed',\n",
              " 'hmm',\n",
              " 'uncle',\n",
              " 'informed',\n",
              " 'paying',\n",
              " 'school',\n",
              " 'directly',\n",
              " 'food',\n",
              " 'private',\n",
              " 'account',\n",
              " 'statement',\n",
              " 'unredeemed',\n",
              " 'points',\n",
              " 'identifier',\n",
              " 'expires',\n",
              " 'caller',\n",
              " 'landline',\n",
              " 'box',\n",
              " 'wr',\n",
              " 'apples',\n",
              " 'pairs',\n",
              " 'todays',\n",
              " 'voda',\n",
              " 'numbers',\n",
              " 'ending',\n",
              " 'award',\n",
              " 'match',\n",
              " 'quoting',\n",
              " 'standard',\n",
              " 'rates',\n",
              " 'app',\n",
              " 'sao',\n",
              " 'mu',\n",
              " 'predict',\n",
              " 'buying',\n",
              " 'yetunde',\n",
              " 'sent',\n",
              " 'bother',\n",
              " 'sending',\n",
              " 'involve',\n",
              " 'imposed',\n",
              " 'apologise',\n",
              " 'girl',\n",
              " 'del',\n",
              " 'bak',\n",
              " 'accomodate',\n",
              " 'answer',\n",
              " 'sunshine',\n",
              " 'quiz',\n",
              " 'top',\n",
              " 'sony',\n",
              " 'dvd',\n",
              " 'player',\n",
              " 'country',\n",
              " 'algarve',\n",
              " 'sp',\n",
              " 'tyrone',\n",
              " 'laid',\n",
              " 'dogging',\n",
              " 'locations',\n",
              " 'direct',\n",
              " 'join',\n",
              " 'largest',\n",
              " 'bt',\n",
              " 'gravel',\n",
              " 'nt',\n",
              " 'ec',\n",
              " 'haf',\n",
              " 'msn',\n",
              " 'hotmail',\n",
              " 'rooms',\n",
              " 'befor',\n",
              " 'activities',\n",
              " 'chat',\n",
              " 'svc',\n",
              " 'hardcore',\n",
              " 'services',\n",
              " 'age',\n",
              " 'yr',\n",
              " 'lazy',\n",
              " 'type',\n",
              " 'lect',\n",
              " 'pouch',\n",
              " 'sir',\n",
              " 'mail',\n",
              " 'swt',\n",
              " 'tired',\n",
              " 'little',\n",
              " 'lovable',\n",
              " 'persons',\n",
              " 'coz',\n",
              " 'occupy',\n",
              " 'biggest',\n",
              " 'hearts',\n",
              " 'gud',\n",
              " 'ni',\n",
              " 'open',\n",
              " 'ya',\n",
              " 'dot',\n",
              " 'whats',\n",
              " 'staff',\n",
              " 'taking',\n",
              " 'replied',\n",
              " 'randy',\n",
              " 'sexy',\n",
              " 'female',\n",
              " 'local',\n",
              " 'luv',\n",
              " 'ltd',\n",
              " 'begin',\n",
              " 'qatar',\n",
              " 'pray',\n",
              " 'hard',\n",
              " 'deleted',\n",
              " 'birla',\n",
              " 'soft',\n",
              " 'wine',\n",
              " 'flowing',\n",
              " 'thk',\n",
              " 'plaza',\n",
              " 'typical',\n",
              " 'everywhere',\n",
              " 'dirt',\n",
              " 'floor',\n",
              " 'windows',\n",
              " 'shirt',\n",
              " 'sometimes',\n",
              " 'mouth',\n",
              " 'dream',\n",
              " 'without',\n",
              " 'chores',\n",
              " 'joy',\n",
              " 'lots',\n",
              " 'tv',\n",
              " 'exist',\n",
              " 'hail',\n",
              " 'mist',\n",
              " 'become',\n",
              " 'leaving',\n",
              " 'house',\n",
              " 'interview',\n",
              " 'boy',\n",
              " 'missing',\n",
              " 'years',\n",
              " 'arrange',\n",
              " 'keep',\n",
              " 'safe',\n",
              " 'envy',\n",
              " 'everyone',\n",
              " 'parents',\n",
              " 'hand',\n",
              " 'excited',\n",
              " 'spend',\n",
              " 'inviting',\n",
              " 'friend',\n",
              " 'order',\n",
              " 'content',\n",
              " 'goto',\n",
              " 'internet',\n",
              " 'menu',\n",
              " 'cultures',\n",
              " 'module',\n",
              " 'avoid',\n",
              " 'wit',\n",
              " 'beloved',\n",
              " 'escape',\n",
              " 'fancy',\n",
              " 'bridge',\n",
              " 'needs',\n",
              " 'lager',\n",
              " 'completely',\n",
              " 'form',\n",
              " 'clark',\n",
              " 'also',\n",
              " 'utter',\n",
              " 'waste',\n",
              " 'axis',\n",
              " 'bank',\n",
              " 'hmmm',\n",
              " 'hop',\n",
              " 'muz',\n",
              " 'discuss',\n",
              " 'liao',\n",
              " 'coming',\n",
              " 'bloody',\n",
              " 'hell',\n",
              " 'cant',\n",
              " 'believe',\n",
              " 'surname',\n",
              " 'mr',\n",
              " 'ill',\n",
              " 'clue',\n",
              " 'spanish',\n",
              " 'begins',\n",
              " 'bath',\n",
              " 'carlos',\n",
              " 'mall',\n",
              " 'turns',\n",
              " 'staying',\n",
              " 'til',\n",
              " 'smoke',\n",
              " 'worth',\n",
              " 'doesnt',\n",
              " 'log',\n",
              " 'spoke',\n",
              " 'satisfied',\n",
              " 'experience',\n",
              " 'toll',\n",
              " 'lifted',\n",
              " 'hopes',\n",
              " 'offer',\n",
              " 'especially',\n",
              " 'approaches',\n",
              " 'studying',\n",
              " 'anyways',\n",
              " 'gr',\n",
              " 'trust',\n",
              " 'guys',\n",
              " 'bye',\n",
              " 'handsome',\n",
              " 'finding',\n",
              " 'working',\n",
              " 'towards',\n",
              " 'mummy',\n",
              " 'awesome',\n",
              " 'minute',\n",
              " 'freephone',\n",
              " 'xmas',\n",
              " 'radio',\n",
              " 'jus',\n",
              " 'bathe',\n",
              " 'sis',\n",
              " 'using',\n",
              " 'finishes',\n",
              " 'unique',\n",
              " 'th',\n",
              " 'august',\n",
              " 'joined',\n",
              " 'league',\n",
              " 'touch',\n",
              " 'deal',\n",
              " 'personal',\n",
              " 'finally',\n",
              " 'completed',\n",
              " 'course',\n",
              " 'however',\n",
              " 'suggest',\n",
              " 'stays',\n",
              " 'able',\n",
              " 'ors',\n",
              " 'every',\n",
              " 'stool',\n",
              " 'settled',\n",
              " 'wishin',\n",
              " 'hav',\n",
              " 'story',\n",
              " 'hamster',\n",
              " 'dead',\n",
              " 'tmr',\n",
              " 'orchard',\n",
              " 'mrt',\n",
              " 'kate',\n",
              " 'evening',\n",
              " 'found',\n",
              " 'enc',\n",
              " 'bucks',\n",
              " 'darlin',\n",
              " 'ive',\n",
              " 'college',\n",
              " 'refilled',\n",
              " 'successfully',\n",
              " 'inr',\n",
              " 'decimal',\n",
              " 'prepaid',\n",
              " 'balance',\n",
              " 'rs',\n",
              " 'transaction',\n",
              " 'id',\n",
              " 'kr',\n",
              " 'goodmorning',\n",
              " 'sleeping',\n",
              " 'ga',\n",
              " 'alter',\n",
              " 'dat',\n",
              " 'ericsson',\n",
              " 'oso',\n",
              " 'dats',\n",
              " 'straight',\n",
              " 'dogg',\n",
              " 'connection',\n",
              " 'refund',\n",
              " 'bill',\n",
              " 'shoot',\n",
              " 'big',\n",
              " 'ready',\n",
              " 'break',\n",
              " 'rewarding',\n",
              " 'semester',\n",
              " 'study',\n",
              " 'noe',\n",
              " 'leh',\n",
              " 'sounds',\n",
              " 'heading',\n",
              " 'prediction',\n",
              " 'slept',\n",
              " 'past',\n",
              " 'nights',\n",
              " 'easy',\n",
              " 'sen',\n",
              " 'exam',\n",
              " 'march',\n",
              " 'atm',\n",
              " 'register',\n",
              " 'os',\n",
              " 'called',\n",
              " 'installing',\n",
              " 'disk',\n",
              " 'important',\n",
              " 'files',\n",
              " 'system',\n",
              " 'repair',\n",
              " 'shop',\n",
              " 'happen',\n",
              " 'romantic',\n",
              " 'nite',\n",
              " 'scenery',\n",
              " 'collect',\n",
              " 'tc',\n",
              " 'biz',\n",
              " 'gbp',\n",
              " 'appreciate',\n",
              " 'partner',\n",
              " 'career',\n",
              " 'start',\n",
              " 'horo',\n",
              " 'followed',\n",
              " 'star',\n",
              " 'sign',\n",
              " 'aries',\n",
              " 'company',\n",
              " 'po',\n",
              " 'strict',\n",
              " 'teacher',\n",
              " 'teaches',\n",
              " 'conducts',\n",
              " 'lessons',\n",
              " 'gandhipuram',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EofbytYVro8H"
      },
      "source": [
        "def remove_word(sen):\n",
        "  word_list = []\n",
        "  tok = word_tokenize(sen)\n",
        "  for word in tok:\n",
        "    if word in word_in_glove:\n",
        "        word_list.append(word)\n",
        "  new_sen = \" \".join(word_list)\n",
        "  return new_sen"
      ],
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Kj3oE6q2ER"
      },
      "source": [
        "data['text_n'] = data['text_n'].apply(lambda x: remove_word(x))"
      ],
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJAybNcn_S9C"
      },
      "source": [
        "#### 문장 array 변환나 및 padding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHHYIYJwcAyQ"
      },
      "source": [
        "text_list = []\n",
        "for i in data.text_n:\n",
        "  text_list.append(str(i))"
      ],
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zuVVBhh_YuS"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_list)\n",
        "sequences = tokenizer.texts_to_sequences(text_list)"
      ],
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ef0nwGlcu_B",
        "outputId": "36ada42e-ce92-4034-ab34-f3053800ad4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len=max(len(word_tokenize(l)) for l in data.text_n)\n",
        "max_len"
      ],
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 433
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlLDsGhh_bZD"
      },
      "source": [
        "X = pad_sequences(sequences, maxlen = max_len)"
      ],
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muOWg_EPgUDV"
      },
      "source": [
        "idx_encode = preprocessing.LabelEncoder()\n",
        "idx_encode.fit(data.isSpam)\n",
        "\n",
        "y = idx_encode.transform(data.isSpam)"
      ],
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUZr_RD3hMRL",
        "outputId": "1deb8ec3-859e-4b76-9d85-9f4d8ec6cd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "print(X[0])\n",
        "print(y[0])"
      ],
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    8 3429  649  580  502 1074   49  219  802 2392 1075   10 3430\n",
            "   57]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YadRoJ6_iXl"
      },
      "source": [
        "#### 임베딩 테이블 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNBmSLHk_A1T"
      },
      "source": [
        "#우리가 토큰화 한 단어 들 중 glove에서 학습된 단어 벡터가 무엇인지 알아보자\n",
        "word_in_glove = []\n",
        "unknown = []\n",
        "for word in unique_word_list:\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        word_in_glove.append(word)\n",
        "    if embedding_vector is None:\n",
        "        unknown.append(word)"
      ],
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEChvOv3AIrp",
        "outputId": "b5b779c8-190d-4447-c517-08278432f8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(word_in_glove)"
      ],
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 438
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-9YjMoAP_r"
      },
      "source": [
        "for ind, word in enumerate(word_in_glove):\n",
        "  dict[word] = ind"
      ],
      "execution_count": 439,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FP1Zq3cBR6A",
        "outputId": "ca0b452a-7556-4fa6-e877-dae181a4c0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dict"
      ],
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'padding_idx': 0,\n",
              " 'unk_idx': 1,\n",
              " 'go': 0,\n",
              " 'jurong': 1,\n",
              " 'point': 2,\n",
              " 'crazy': 3,\n",
              " 'available': 4,\n",
              " 'bugis': 5,\n",
              " 'great': 6,\n",
              " 'world': 7,\n",
              " 'la': 8,\n",
              " 'buffet': 9,\n",
              " 'cine': 10,\n",
              " 'got': 11,\n",
              " 'amore': 12,\n",
              " 'wat': 13,\n",
              " 'ok': 14,\n",
              " 'lar': 15,\n",
              " 'joking': 16,\n",
              " 'wif': 17,\n",
              " 'oni': 18,\n",
              " 'free': 19,\n",
              " 'entry': 20,\n",
              " 'comp': 21,\n",
              " 'win': 22,\n",
              " 'fa': 23,\n",
              " 'cup': 24,\n",
              " 'final': 25,\n",
              " 'tkts': 26,\n",
              " 'st': 27,\n",
              " 'may': 28,\n",
              " 'text': 29,\n",
              " 'receive': 30,\n",
              " 'question': 31,\n",
              " 'std': 32,\n",
              " 'txt': 33,\n",
              " 'rate': 34,\n",
              " 'apply': 35,\n",
              " 'dun': 36,\n",
              " 'say': 37,\n",
              " 'early': 38,\n",
              " 'hor': 39,\n",
              " 'already': 40,\n",
              " 'nah': 41,\n",
              " 'think': 42,\n",
              " 'goes': 43,\n",
              " 'usf': 44,\n",
              " 'lives': 45,\n",
              " 'around': 46,\n",
              " 'though': 47,\n",
              " 'hey': 48,\n",
              " 'darling': 49,\n",
              " 'week': 50,\n",
              " 'word': 51,\n",
              " 'back': 52,\n",
              " 'like': 53,\n",
              " 'fun': 54,\n",
              " 'still': 55,\n",
              " 'tb': 56,\n",
              " 'xxx': 57,\n",
              " 'send': 58,\n",
              " 'rcv': 59,\n",
              " 'even': 60,\n",
              " 'brother': 61,\n",
              " 'speak': 62,\n",
              " 'treat': 63,\n",
              " 'aids': 64,\n",
              " 'patent': 65,\n",
              " 'per': 66,\n",
              " 'request': 67,\n",
              " 'melle': 68,\n",
              " 'oru': 69,\n",
              " 'set': 70,\n",
              " 'callers': 71,\n",
              " 'press': 72,\n",
              " 'copy': 73,\n",
              " 'friends': 74,\n",
              " 'winner': 75,\n",
              " 'valued': 76,\n",
              " 'network': 77,\n",
              " 'customer': 78,\n",
              " 'selected': 79,\n",
              " 'prize': 80,\n",
              " 'reward': 81,\n",
              " 'claim': 82,\n",
              " 'call': 83,\n",
              " 'code': 84,\n",
              " 'kl': 85,\n",
              " 'valid': 86,\n",
              " 'hours': 87,\n",
              " 'mobile': 88,\n",
              " 'months': 89,\n",
              " 'entitled': 90,\n",
              " 'update': 91,\n",
              " 'latest': 92,\n",
              " 'colour': 93,\n",
              " 'mobiles': 94,\n",
              " 'camera': 95,\n",
              " 'co': 96,\n",
              " 'gon': 97,\n",
              " 'na': 98,\n",
              " 'home': 99,\n",
              " 'soon': 100,\n",
              " 'want': 101,\n",
              " 'talk': 102,\n",
              " 'stuff': 103,\n",
              " 'anymore': 104,\n",
              " 'tonight': 105,\n",
              " 'cried': 106,\n",
              " 'enough': 107,\n",
              " 'today': 108,\n",
              " 'six': 109,\n",
              " 'chances': 110,\n",
              " 'cash': 111,\n",
              " 'pounds': 112,\n",
              " 'csh': 113,\n",
              " 'cost': 114,\n",
              " 'day': 115,\n",
              " 'days': 116,\n",
              " 'reply': 117,\n",
              " 'hl': 118,\n",
              " 'info': 119,\n",
              " 'urgent': 120,\n",
              " 'membership': 121,\n",
              " 'jackpot': 122,\n",
              " 'www': 123,\n",
              " 'net': 124,\n",
              " 'rw': 125,\n",
              " 'searching': 126,\n",
              " 'right': 127,\n",
              " 'words': 128,\n",
              " 'thank': 129,\n",
              " 'breather': 130,\n",
              " 'promise': 131,\n",
              " 'wont': 132,\n",
              " 'take': 133,\n",
              " 'help': 134,\n",
              " 'granted': 135,\n",
              " 'fulfil': 136,\n",
              " 'wonderful': 137,\n",
              " 'blessing': 138,\n",
              " 'times': 139,\n",
              " 'date': 140,\n",
              " 'sunday': 141,\n",
              " 'use': 142,\n",
              " 'credit': 143,\n",
              " 'click': 144,\n",
              " 'wap': 145,\n",
              " 'link': 146,\n",
              " 'next': 147,\n",
              " 'message': 148,\n",
              " 'http': 149,\n",
              " 'com': 150,\n",
              " 'oh': 151,\n",
              " 'watching': 152,\n",
              " 'eh': 153,\n",
              " 'remember': 154,\n",
              " 'spell': 155,\n",
              " 'name': 156,\n",
              " 'yes': 157,\n",
              " 'naughty': 158,\n",
              " 'make': 159,\n",
              " 'wet': 160,\n",
              " 'fine': 161,\n",
              " 'way': 162,\n",
              " 'feel': 163,\n",
              " 'gota': 164,\n",
              " 'england': 165,\n",
              " 'macedonia': 166,\n",
              " 'dont': 167,\n",
              " 'miss': 168,\n",
              " 'goals': 169,\n",
              " 'team': 170,\n",
              " 'news': 171,\n",
              " 'ur': 172,\n",
              " 'national': 173,\n",
              " 'eg': 174,\n",
              " 'try': 175,\n",
              " 'wales': 176,\n",
              " 'scotland': 177,\n",
              " 'seriously': 178,\n",
              " 'going': 179,\n",
              " 'ha': 180,\n",
              " 'pay': 181,\n",
              " 'first': 182,\n",
              " 'da': 183,\n",
              " 'stock': 184,\n",
              " 'comin': 185,\n",
              " 'aft': 186,\n",
              " 'finish': 187,\n",
              " 'lunch': 188,\n",
              " 'str': 189,\n",
              " 'lor': 190,\n",
              " 'ard': 191,\n",
              " 'smth': 192,\n",
              " 'alright': 193,\n",
              " 'meet': 194,\n",
              " 'sooner': 195,\n",
              " 'forced': 196,\n",
              " 'eat': 197,\n",
              " 'slice': 198,\n",
              " 'really': 199,\n",
              " 'hungry': 200,\n",
              " 'tho': 201,\n",
              " 'sucks': 202,\n",
              " 'mark': 203,\n",
              " 'getting': 204,\n",
              " 'worried': 205,\n",
              " 'knows': 206,\n",
              " 'sick': 207,\n",
              " 'turn': 208,\n",
              " 'pizza': 209,\n",
              " 'lol': 210,\n",
              " 'always': 211,\n",
              " 'convincing': 212,\n",
              " 'catch': 213,\n",
              " 'bus': 214,\n",
              " 'frying': 215,\n",
              " 'egg': 216,\n",
              " 'tea': 217,\n",
              " 'eating': 218,\n",
              " 'mom': 219,\n",
              " 'left': 220,\n",
              " 'dinner': 221,\n",
              " 'love': 222,\n",
              " 'amp': 223,\n",
              " 'packing': 224,\n",
              " 'car': 225,\n",
              " 'let': 226,\n",
              " 'know': 227,\n",
              " 'room': 228,\n",
              " 'ahhh': 229,\n",
              " 'work': 230,\n",
              " 'vaguely': 231,\n",
              " 'wait': 232,\n",
              " 'clear': 233,\n",
              " 'sure': 234,\n",
              " 'sarcastic': 235,\n",
              " 'live': 236,\n",
              " 'us': 237,\n",
              " 'yeah': 238,\n",
              " 'apologetic': 239,\n",
              " 'fallen': 240,\n",
              " 'actin': 241,\n",
              " 'spoilt': 242,\n",
              " 'child': 243,\n",
              " 'caught': 244,\n",
              " 'till': 245,\n",
              " 'badly': 246,\n",
              " 'cheers': 247,\n",
              " 'tell': 248,\n",
              " 'anything': 249,\n",
              " 'fear': 250,\n",
              " 'fainting': 251,\n",
              " 'housework': 252,\n",
              " 'quick': 253,\n",
              " 'cuppa': 254,\n",
              " 'thanks': 255,\n",
              " 'subscription': 256,\n",
              " 'ringtone': 257,\n",
              " 'uk': 258,\n",
              " 'charged': 259,\n",
              " 'month': 260,\n",
              " 'please': 261,\n",
              " 'confirm': 262,\n",
              " 'replying': 263,\n",
              " 'yup': 264,\n",
              " 'look': 265,\n",
              " 'timings': 266,\n",
              " 'msg': 267,\n",
              " 'xuhui': 268,\n",
              " 'learn': 269,\n",
              " 'nd': 270,\n",
              " 'lesson': 271,\n",
              " 'oops': 272,\n",
              " 'roommate': 273,\n",
              " 'done': 274,\n",
              " 'see': 275,\n",
              " 'letter': 276,\n",
              " 'decide': 277,\n",
              " 'hello': 278,\n",
              " 'saturday': 279,\n",
              " 'texting': 280,\n",
              " 'decided': 281,\n",
              " 'tomo': 282,\n",
              " 'trying': 283,\n",
              " 'invite': 284,\n",
              " 'pls': 285,\n",
              " 'ahead': 286,\n",
              " 'watts': 287,\n",
              " 'wanted': 288,\n",
              " 'weekend': 289,\n",
              " 'abiola': 290,\n",
              " 'forget': 291,\n",
              " 'need': 292,\n",
              " 'crave': 293,\n",
              " 'sweet': 294,\n",
              " 'arabian': 295,\n",
              " 'steed': 296,\n",
              " 'yummy': 297,\n",
              " 'rodger': 298,\n",
              " 'burns': 299,\n",
              " 'tried': 300,\n",
              " 'sms': 301,\n",
              " 'nokia': 302,\n",
              " 'camcorder': 303,\n",
              " 'delivery': 304,\n",
              " 'tomorrow': 305,\n",
              " 'seeing': 306,\n",
              " 'hope': 307,\n",
              " 'man': 308,\n",
              " 'well': 309,\n",
              " 'endowed': 310,\n",
              " 'lt': 311,\n",
              " 'gt': 312,\n",
              " 'inches': 313,\n",
              " 'calls': 314,\n",
              " 'messages': 315,\n",
              " 'missed': 316,\n",
              " 'get': 317,\n",
              " 'hep': 318,\n",
              " 'immunisation': 319,\n",
              " 'nigeria': 320,\n",
              " 'fair': 321,\n",
              " 'hopefully': 322,\n",
              " 'tyler': 323,\n",
              " 'could': 324,\n",
              " 'maybe': 325,\n",
              " 'ask': 326,\n",
              " 'bit': 327,\n",
              " 'stubborn': 328,\n",
              " 'hospital': 329,\n",
              " 'kept': 330,\n",
              " 'telling': 331,\n",
              " 'weak': 332,\n",
              " 'sucker': 333,\n",
              " 'hospitals': 334,\n",
              " 'suckers': 335,\n",
              " 'time': 336,\n",
              " 'saw': 337,\n",
              " 'class': 338,\n",
              " 'gram': 339,\n",
              " 'usually': 340,\n",
              " 'runs': 341,\n",
              " 'half': 342,\n",
              " 'eighth': 343,\n",
              " 'smarter': 344,\n",
              " 'gets': 345,\n",
              " 'almost': 346,\n",
              " 'whole': 347,\n",
              " 'second': 348,\n",
              " 'fyi': 349,\n",
              " 'ride': 350,\n",
              " 'morning': 351,\n",
              " 'crashing': 352,\n",
              " 'place': 353,\n",
              " 'wow': 354,\n",
              " 'never': 355,\n",
              " 'realized': 356,\n",
              " 'embarassed': 357,\n",
              " 'accomodations': 358,\n",
              " 'thought': 359,\n",
              " 'liked': 360,\n",
              " 'since': 361,\n",
              " 'best': 362,\n",
              " 'seemed': 363,\n",
              " 'happy': 364,\n",
              " 'cave': 365,\n",
              " 'sorry': 366,\n",
              " 'give': 367,\n",
              " 'offered': 368,\n",
              " 'embarassing': 369,\n",
              " 'ac': 370,\n",
              " 'new': 371,\n",
              " 'jersey': 372,\n",
              " 'devils': 373,\n",
              " 'detroit': 374,\n",
              " 'red': 375,\n",
              " 'wings': 376,\n",
              " 'play': 377,\n",
              " 'ice': 378,\n",
              " 'hockey': 379,\n",
              " 'correct': 380,\n",
              " 'incorrect': 381,\n",
              " 'end': 382,\n",
              " 'mallika': 383,\n",
              " 'sherawat': 384,\n",
              " 'yesterday': 385,\n",
              " 'find': 386,\n",
              " 'url': 387,\n",
              " 'congrats': 388,\n",
              " 'year': 389,\n",
              " 'special': 390,\n",
              " 'cinema': 391,\n",
              " 'pass': 392,\n",
              " 'matrix': 393,\n",
              " 'starwars': 394,\n",
              " 'etc': 395,\n",
              " 'bx': 396,\n",
              " 'ip': 397,\n",
              " 'pm': 398,\n",
              " 'later': 399,\n",
              " 'meeting': 400,\n",
              " 'reached': 401,\n",
              " 'sehwag': 402,\n",
              " 'odi': 403,\n",
              " 'series': 404,\n",
              " 'pick': 405,\n",
              " 'burger': 406,\n",
              " 'move': 407,\n",
              " 'pain': 408,\n",
              " 'killing': 409,\n",
              " 'good': 410,\n",
              " 'joke': 411,\n",
              " 'girls': 412,\n",
              " 'situation': 413,\n",
              " 'seekers': 414,\n",
              " 'part': 415,\n",
              " 'checking': 416,\n",
              " 'iq': 417,\n",
              " 'roommates': 418,\n",
              " 'took': 419,\n",
              " 'forever': 420,\n",
              " 'come': 421,\n",
              " 'double': 422,\n",
              " 'check': 423,\n",
              " 'hair': 424,\n",
              " 'dresser': 425,\n",
              " 'said': 426,\n",
              " 'wun': 427,\n",
              " 'cut': 428,\n",
              " 'short': 429,\n",
              " 'nice': 430,\n",
              " 'pleased': 431,\n",
              " 'advise': 432,\n",
              " 'following': 433,\n",
              " 'recent': 434,\n",
              " 'review': 435,\n",
              " 'mob': 436,\n",
              " 'awarded': 437,\n",
              " 'bonus': 438,\n",
              " 'song': 439,\n",
              " 'dedicated': 440,\n",
              " 'dedicate': 441,\n",
              " 'valuable': 442,\n",
              " 'complimentary': 443,\n",
              " 'trip': 444,\n",
              " 'trav': 445,\n",
              " 'aco': 446,\n",
              " 'dis': 447,\n",
              " 'ls': 448,\n",
              " 'aj': 449,\n",
              " 'hear': 450,\n",
              " 'divorce': 451,\n",
              " 'barbie': 452,\n",
              " 'comes': 453,\n",
              " 'ken': 454,\n",
              " 'plane': 455,\n",
              " 'wah': 456,\n",
              " 'lucky': 457,\n",
              " 'save': 458,\n",
              " 'money': 459,\n",
              " 'hee': 460,\n",
              " 'finished': 461,\n",
              " 'hi': 462,\n",
              " 'babe': 463,\n",
              " 'im': 464,\n",
              " 'wan': 465,\n",
              " 'something': 466,\n",
              " 'xx': 467,\n",
              " 'performed': 468,\n",
              " 'waiting': 469,\n",
              " 'machan': 470,\n",
              " 'thats': 471,\n",
              " 'cool': 472,\n",
              " 'gentleman': 473,\n",
              " 'dignity': 474,\n",
              " 'respect': 475,\n",
              " 'peoples': 476,\n",
              " 'much': 477,\n",
              " 'shy': 478,\n",
              " 'pa': 479,\n",
              " 'operate': 480,\n",
              " 'looking': 481,\n",
              " 'job': 482,\n",
              " 'ta': 483,\n",
              " 'earn': 484,\n",
              " 'ah': 485,\n",
              " 'stop': 486,\n",
              " 'real': 487,\n",
              " 'yo': 488,\n",
              " 'tickets': 489,\n",
              " 'one': 490,\n",
              " 'jacket': 491,\n",
              " 'used': 492,\n",
              " 'multis': 493,\n",
              " 'started': 494,\n",
              " 'requests': 495,\n",
              " 'came': 496,\n",
              " 'bed': 497,\n",
              " 'coins': 498,\n",
              " 'factory': 499,\n",
              " 'ela': 500,\n",
              " 'kano': 501,\n",
              " 'il': 502,\n",
              " 'download': 503,\n",
              " 'wen': 504,\n",
              " 'stand': 505,\n",
              " 'close': 506,\n",
              " 'another': 507,\n",
              " 'night': 508,\n",
              " 'spent': 509,\n",
              " 'late': 510,\n",
              " 'afternoon': 511,\n",
              " 'casualty': 512,\n",
              " 'means': 513,\n",
              " 'moro': 514,\n",
              " 'includes': 515,\n",
              " 'sheets': 516,\n",
              " 'smile': 517,\n",
              " 'pleasure': 518,\n",
              " 'trouble': 519,\n",
              " 'pours': 520,\n",
              " 'rain': 521,\n",
              " 'sum': 522,\n",
              " 'hurts': 523,\n",
              " 'someone': 524,\n",
              " 'loves': 525,\n",
              " 'smiling': 526,\n",
              " 'service': 527,\n",
              " 'representative': 528,\n",
              " 'guaranteed': 529,\n",
              " 'havent': 530,\n",
              " 'planning': 531,\n",
              " 'buy': 532,\n",
              " 'lido': 533,\n",
              " 'show': 534,\n",
              " 'collected': 535,\n",
              " 'simply': 536,\n",
              " 'password': 537,\n",
              " 'mix': 538,\n",
              " 'verify': 539,\n",
              " 'usher': 540,\n",
              " 'britney': 541,\n",
              " 'fml': 542,\n",
              " 'telugu': 543,\n",
              " 'movie': 544,\n",
              " 'abt': 545,\n",
              " 'loads': 546,\n",
              " 'loans': 547,\n",
              " 'wk': 548,\n",
              " 'run': 549,\n",
              " 'forgot': 550,\n",
              " 'hairdressers': 551,\n",
              " 'appointment': 552,\n",
              " 'four': 553,\n",
              " 'shower': 554,\n",
              " 'beforehand': 555,\n",
              " 'cause': 556,\n",
              " 'prob': 557,\n",
              " 'ham': 558,\n",
              " 'nothing': 559,\n",
              " 'else': 560,\n",
              " 'okay': 561,\n",
              " 'price': 562,\n",
              " 'long': 563,\n",
              " 'legal': 564,\n",
              " 'ave': 565,\n",
              " 'ams': 566,\n",
              " 'gone': 567,\n",
              " 'driving': 568,\n",
              " 'test': 569,\n",
              " 'yet': 570,\n",
              " 'mean': 571,\n",
              " 'guess': 572,\n",
              " 'gave': 573,\n",
              " 'boston': 574,\n",
              " 'men': 575,\n",
              " 'changed': 576,\n",
              " 'search': 577,\n",
              " 'location': 578,\n",
              " 'nyc': 579,\n",
              " 'cuz': 580,\n",
              " 'page': 581,\n",
              " 'says': 582,\n",
              " 'umma': 583,\n",
              " 'life': 584,\n",
              " 'vava': 585,\n",
              " 'lot': 586,\n",
              " 'dear': 587,\n",
              " 'wishes': 588,\n",
              " 'birthday': 589,\n",
              " 'making': 590,\n",
              " 'truly': 591,\n",
              " 'memorable': 592,\n",
              " 'hit': 593,\n",
              " 'would': 594,\n",
              " 'address': 595,\n",
              " 'considering': 596,\n",
              " 'computer': 597,\n",
              " 'minecraft': 598,\n",
              " 'server': 599,\n",
              " 'grumpy': 600,\n",
              " 'old': 601,\n",
              " 'people': 602,\n",
              " 'better': 603,\n",
              " 'lying': 604,\n",
              " 'jokes': 605,\n",
              " 'worry': 606,\n",
              " 'busy': 607,\n",
              " 'plural': 608,\n",
              " 'noun': 609,\n",
              " 'research': 610,\n",
              " 'cos': 611,\n",
              " 'things': 612,\n",
              " 'scared': 613,\n",
              " 'mah': 614,\n",
              " 'loud': 615,\n",
              " 'gent': 616,\n",
              " 'contact': 617,\n",
              " 'last': 618,\n",
              " 'weekends': 619,\n",
              " 'draw': 620,\n",
              " 'shows': 621,\n",
              " 'hrs': 622,\n",
              " 'ppm': 623,\n",
              " 'wa': 624,\n",
              " 'sentence': 625,\n",
              " 'formal': 626,\n",
              " 'anyway': 627,\n",
              " 'juz': 628,\n",
              " 'tt': 629,\n",
              " 'eatin': 630,\n",
              " 'puttin': 631,\n",
              " 'weight': 632,\n",
              " 'haha': 633,\n",
              " 'happened': 634,\n",
              " 'entered': 635,\n",
              " 'cabin': 636,\n",
              " 'boss': 637,\n",
              " 'felt': 638,\n",
              " 'invited': 639,\n",
              " 'apartment': 640,\n",
              " 'went': 641,\n",
              " 'specially': 642,\n",
              " 'holiday': 643,\n",
              " 'flights': 644,\n",
              " 'inc': 645,\n",
              " 'operator': 646,\n",
              " 'min': 647,\n",
              " 'must': 648,\n",
              " 'friday': 649,\n",
              " 'potato': 650,\n",
              " 'ratio': 651,\n",
              " 'tortilla': 652,\n",
              " 'needed': 653,\n",
              " 'hmm': 654,\n",
              " 'uncle': 655,\n",
              " 'informed': 656,\n",
              " 'paying': 657,\n",
              " 'school': 658,\n",
              " 'directly': 659,\n",
              " 'food': 660,\n",
              " 'private': 661,\n",
              " 'account': 662,\n",
              " 'statement': 663,\n",
              " 'unredeemed': 664,\n",
              " 'points': 665,\n",
              " 'identifier': 666,\n",
              " 'expires': 667,\n",
              " 'caller': 668,\n",
              " 'landline': 669,\n",
              " 'box': 670,\n",
              " 'wr': 671,\n",
              " 'apples': 672,\n",
              " 'pairs': 673,\n",
              " 'todays': 674,\n",
              " 'voda': 675,\n",
              " 'numbers': 676,\n",
              " 'ending': 677,\n",
              " 'award': 678,\n",
              " 'match': 679,\n",
              " 'quoting': 680,\n",
              " 'standard': 681,\n",
              " 'rates': 682,\n",
              " 'app': 683,\n",
              " 'sao': 684,\n",
              " 'mu': 685,\n",
              " 'predict': 686,\n",
              " 'buying': 687,\n",
              " 'yetunde': 688,\n",
              " 'sent': 689,\n",
              " 'bother': 690,\n",
              " 'sending': 691,\n",
              " 'involve': 692,\n",
              " 'imposed': 693,\n",
              " 'apologise': 694,\n",
              " 'girl': 695,\n",
              " 'del': 696,\n",
              " 'bak': 697,\n",
              " 'accomodate': 698,\n",
              " 'answer': 699,\n",
              " 'sunshine': 700,\n",
              " 'quiz': 701,\n",
              " 'top': 702,\n",
              " 'sony': 703,\n",
              " 'dvd': 704,\n",
              " 'player': 705,\n",
              " 'country': 706,\n",
              " 'algarve': 707,\n",
              " 'sp': 708,\n",
              " 'tyrone': 709,\n",
              " 'laid': 710,\n",
              " 'dogging': 711,\n",
              " 'locations': 712,\n",
              " 'direct': 713,\n",
              " 'join': 714,\n",
              " 'largest': 715,\n",
              " 'bt': 716,\n",
              " 'gravel': 717,\n",
              " 'nt': 718,\n",
              " 'ec': 719,\n",
              " 'haf': 720,\n",
              " 'msn': 721,\n",
              " 'hotmail': 722,\n",
              " 'rooms': 723,\n",
              " 'befor': 724,\n",
              " 'activities': 725,\n",
              " 'chat': 726,\n",
              " 'svc': 727,\n",
              " 'hardcore': 728,\n",
              " 'services': 729,\n",
              " 'age': 730,\n",
              " 'yr': 731,\n",
              " 'lazy': 732,\n",
              " 'type': 733,\n",
              " 'lect': 734,\n",
              " 'pouch': 735,\n",
              " 'sir': 736,\n",
              " 'mail': 737,\n",
              " 'swt': 738,\n",
              " 'tired': 739,\n",
              " 'little': 740,\n",
              " 'lovable': 741,\n",
              " 'persons': 742,\n",
              " 'coz': 743,\n",
              " 'occupy': 744,\n",
              " 'biggest': 745,\n",
              " 'hearts': 746,\n",
              " 'gud': 747,\n",
              " 'ni': 748,\n",
              " 'open': 749,\n",
              " 'ya': 750,\n",
              " 'dot': 751,\n",
              " 'whats': 752,\n",
              " 'staff': 753,\n",
              " 'taking': 754,\n",
              " 'replied': 755,\n",
              " 'randy': 756,\n",
              " 'sexy': 757,\n",
              " 'female': 758,\n",
              " 'local': 759,\n",
              " 'luv': 760,\n",
              " 'ltd': 761,\n",
              " 'begin': 762,\n",
              " 'qatar': 763,\n",
              " 'pray': 764,\n",
              " 'hard': 765,\n",
              " 'deleted': 766,\n",
              " 'birla': 767,\n",
              " 'soft': 768,\n",
              " 'wine': 769,\n",
              " 'flowing': 770,\n",
              " 'thk': 771,\n",
              " 'plaza': 772,\n",
              " 'typical': 773,\n",
              " 'everywhere': 774,\n",
              " 'dirt': 775,\n",
              " 'floor': 776,\n",
              " 'windows': 777,\n",
              " 'shirt': 778,\n",
              " 'sometimes': 779,\n",
              " 'mouth': 780,\n",
              " 'dream': 781,\n",
              " 'without': 782,\n",
              " 'chores': 783,\n",
              " 'joy': 784,\n",
              " 'lots': 785,\n",
              " 'tv': 786,\n",
              " 'exist': 787,\n",
              " 'hail': 788,\n",
              " 'mist': 789,\n",
              " 'become': 790,\n",
              " 'leaving': 791,\n",
              " 'house': 792,\n",
              " 'interview': 793,\n",
              " 'boy': 794,\n",
              " 'missing': 795,\n",
              " 'years': 796,\n",
              " 'arrange': 797,\n",
              " 'keep': 798,\n",
              " 'safe': 799,\n",
              " 'envy': 800,\n",
              " 'everyone': 801,\n",
              " 'parents': 802,\n",
              " 'hand': 803,\n",
              " 'excited': 804,\n",
              " 'spend': 805,\n",
              " 'inviting': 806,\n",
              " 'friend': 807,\n",
              " 'order': 808,\n",
              " 'content': 809,\n",
              " 'goto': 810,\n",
              " 'internet': 811,\n",
              " 'menu': 812,\n",
              " 'cultures': 813,\n",
              " 'module': 814,\n",
              " 'avoid': 815,\n",
              " 'wit': 816,\n",
              " 'beloved': 817,\n",
              " 'escape': 818,\n",
              " 'fancy': 819,\n",
              " 'bridge': 820,\n",
              " 'needs': 821,\n",
              " 'lager': 822,\n",
              " 'completely': 823,\n",
              " 'form': 824,\n",
              " 'clark': 825,\n",
              " 'also': 826,\n",
              " 'utter': 827,\n",
              " 'waste': 828,\n",
              " 'axis': 829,\n",
              " 'bank': 830,\n",
              " 'hmmm': 831,\n",
              " 'hop': 832,\n",
              " 'muz': 833,\n",
              " 'discuss': 834,\n",
              " 'liao': 835,\n",
              " 'coming': 836,\n",
              " 'bloody': 837,\n",
              " 'hell': 838,\n",
              " 'cant': 839,\n",
              " 'believe': 840,\n",
              " 'surname': 841,\n",
              " 'mr': 842,\n",
              " 'ill': 843,\n",
              " 'clue': 844,\n",
              " 'spanish': 845,\n",
              " 'begins': 846,\n",
              " 'bath': 847,\n",
              " 'carlos': 848,\n",
              " 'mall': 849,\n",
              " 'turns': 850,\n",
              " 'staying': 851,\n",
              " 'til': 852,\n",
              " 'smoke': 853,\n",
              " 'worth': 854,\n",
              " 'doesnt': 855,\n",
              " 'log': 856,\n",
              " 'spoke': 857,\n",
              " 'satisfied': 858,\n",
              " 'experience': 859,\n",
              " 'toll': 860,\n",
              " 'lifted': 861,\n",
              " 'hopes': 862,\n",
              " 'offer': 863,\n",
              " 'especially': 864,\n",
              " 'approaches': 865,\n",
              " 'studying': 866,\n",
              " 'anyways': 867,\n",
              " 'gr': 868,\n",
              " 'trust': 869,\n",
              " 'guys': 870,\n",
              " 'bye': 871,\n",
              " 'handsome': 872,\n",
              " 'finding': 873,\n",
              " 'working': 874,\n",
              " 'towards': 875,\n",
              " 'mummy': 876,\n",
              " 'awesome': 877,\n",
              " 'minute': 878,\n",
              " 'freephone': 879,\n",
              " 'xmas': 880,\n",
              " 'radio': 881,\n",
              " 'jus': 882,\n",
              " 'bathe': 883,\n",
              " 'sis': 884,\n",
              " 'using': 885,\n",
              " 'finishes': 886,\n",
              " 'unique': 887,\n",
              " 'th': 888,\n",
              " 'august': 889,\n",
              " 'joined': 890,\n",
              " 'league': 891,\n",
              " 'touch': 892,\n",
              " 'deal': 893,\n",
              " 'personal': 894,\n",
              " 'finally': 895,\n",
              " 'completed': 896,\n",
              " 'course': 897,\n",
              " 'however': 898,\n",
              " 'suggest': 899,\n",
              " 'stays': 900,\n",
              " 'able': 901,\n",
              " 'ors': 902,\n",
              " 'every': 903,\n",
              " 'stool': 904,\n",
              " 'settled': 905,\n",
              " 'wishin': 906,\n",
              " 'hav': 907,\n",
              " 'story': 908,\n",
              " 'hamster': 909,\n",
              " 'dead': 910,\n",
              " 'tmr': 911,\n",
              " 'orchard': 912,\n",
              " 'mrt': 913,\n",
              " 'kate': 914,\n",
              " 'evening': 915,\n",
              " 'found': 916,\n",
              " 'enc': 917,\n",
              " 'bucks': 918,\n",
              " 'darlin': 919,\n",
              " 'ive': 920,\n",
              " 'college': 921,\n",
              " 'refilled': 922,\n",
              " 'successfully': 923,\n",
              " 'inr': 924,\n",
              " 'decimal': 925,\n",
              " 'prepaid': 926,\n",
              " 'balance': 927,\n",
              " 'rs': 928,\n",
              " 'transaction': 929,\n",
              " 'id': 930,\n",
              " 'kr': 931,\n",
              " 'goodmorning': 932,\n",
              " 'sleeping': 933,\n",
              " 'ga': 934,\n",
              " 'alter': 935,\n",
              " 'dat': 936,\n",
              " 'ericsson': 937,\n",
              " 'oso': 938,\n",
              " 'dats': 939,\n",
              " 'straight': 940,\n",
              " 'dogg': 941,\n",
              " 'connection': 942,\n",
              " 'refund': 943,\n",
              " 'bill': 944,\n",
              " 'shoot': 945,\n",
              " 'big': 946,\n",
              " 'ready': 947,\n",
              " 'break': 948,\n",
              " 'rewarding': 949,\n",
              " 'semester': 950,\n",
              " 'study': 951,\n",
              " 'noe': 952,\n",
              " 'leh': 953,\n",
              " 'sounds': 954,\n",
              " 'heading': 955,\n",
              " 'prediction': 956,\n",
              " 'slept': 957,\n",
              " 'past': 958,\n",
              " 'nights': 959,\n",
              " 'easy': 960,\n",
              " 'sen': 961,\n",
              " 'exam': 962,\n",
              " 'march': 963,\n",
              " 'atm': 964,\n",
              " 'register': 965,\n",
              " 'os': 966,\n",
              " 'called': 967,\n",
              " 'installing': 968,\n",
              " 'disk': 969,\n",
              " 'important': 970,\n",
              " 'files': 971,\n",
              " 'system': 972,\n",
              " 'repair': 973,\n",
              " 'shop': 974,\n",
              " 'happen': 975,\n",
              " 'romantic': 976,\n",
              " 'nite': 977,\n",
              " 'scenery': 978,\n",
              " 'collect': 979,\n",
              " 'tc': 980,\n",
              " 'biz': 981,\n",
              " 'gbp': 982,\n",
              " 'appreciate': 983,\n",
              " 'partner': 984,\n",
              " 'career': 985,\n",
              " 'start': 986,\n",
              " 'horo': 987,\n",
              " 'followed': 988,\n",
              " 'star': 989,\n",
              " 'sign': 990,\n",
              " 'aries': 991,\n",
              " 'company': 992,\n",
              " 'po': 993,\n",
              " 'strict': 994,\n",
              " 'teacher': 995,\n",
              " 'teaches': 996,\n",
              " 'conducts': 997,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNrmLnuvANcR"
      },
      "source": [
        "embedding_dim = 100\n",
        "vocab_size=6237\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
      ],
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eeZfQG1Asu-"
      },
      "source": [
        "for word, i in dict.items():\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector "
      ],
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YsEbnhidpZr",
        "outputId": "778b1ae0-d4ef-429a-db8b-9d1ccd91ac7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "embedding_matrix[0]"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.078894  ,  0.46160001,  0.57779002, -0.71636999, -0.13121   ,\n",
              "        0.41859999, -0.29155999,  0.52006   ,  0.089986  , -0.35062   ,\n",
              "        0.51754999,  0.51998001,  0.15218   ,  0.41485   , -0.12377   ,\n",
              "       -0.37222001,  0.0273    ,  0.75673002, -0.8739    ,  0.58934999,\n",
              "        0.46662   ,  0.62918001,  0.092603  , -0.012868  , -0.015169  ,\n",
              "        0.25567001, -0.43024999, -0.77667999,  0.71449   , -0.38339999,\n",
              "       -0.69638002,  0.23522   ,  0.11396   ,  0.02778   ,  0.071357  ,\n",
              "        0.87409002, -0.12809999,  0.063576  ,  0.067867  , -0.50181001,\n",
              "       -0.28523001, -0.072536  , -0.50738001, -0.69139999, -0.53579003,\n",
              "       -0.11361   , -0.38234001, -0.12414   ,  0.011214  , -1.16219997,\n",
              "        0.037057  , -0.18494999,  0.01416   ,  0.87193   , -0.097309  ,\n",
              "       -2.35649991, -0.14554   ,  0.28275001,  2.00530005,  0.23439001,\n",
              "       -0.38297999,  0.69538999, -0.44916001, -0.094157  ,  0.90526998,\n",
              "        0.65763998,  0.27627999,  0.30688   , -0.57780999, -0.22987001,\n",
              "       -0.083043  , -0.57235998, -0.29899999, -0.81111997,  0.039752  ,\n",
              "       -0.05681   , -0.48879001, -0.18091001, -0.28152001, -0.20558999,\n",
              "        0.4932    , -0.033999  , -0.53139001, -0.28297001, -1.44749999,\n",
              "       -0.18685   ,  0.091177  ,  0.11454   , -0.28167999, -0.33565   ,\n",
              "       -0.31663001, -0.1089    ,  0.10111   , -0.23737   , -0.64955002,\n",
              "       -0.26800001,  0.35095999,  0.26352   ,  0.59397   ,  0.26741001])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxZviG1lWBQd"
      },
      "source": [
        "#### train/test data 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVcUmfftWJlc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,\n",
        "                                                   stratify=y, test_size=0.1)"
      ],
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi06_QYPg9MT",
        "outputId": "7bb576e9-76fd-4ec7-c975-229dc4881b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 455,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5014, 71)\n",
            "(5014,)\n",
            "(558, 71)\n",
            "(558,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn1xePRztVBQ"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)"
      ],
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7F7kniptdJH",
        "outputId": "0c836e63-dc5e-4b96-db87-8a90c5102657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3509, 71)\n",
            "(3509,)\n",
            "(1505, 71)\n",
            "(1505,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpP84KLVZQwY"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyE6pbZfLHw",
        "outputId": "35f263a1-e4fe-45de-9870-556d4d5e5645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label_idx={}\n",
        "label_idx['ham']=0\n",
        "label_idx['spam']=1\n",
        "label_idx"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ham': 0, 'spam': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Vn2ge6ZVAY"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense, Input, Flatten, Concatenate"
      ],
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHpCFOa6ZXFV"
      },
      "source": [
        "filter_sizes = [2,3,5]\n",
        "num_filters = 512\n",
        "drop = 0.5"
      ],
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_P_cxbsZZOI",
        "outputId": "83a42110-3fd8-4664-f737-eba47c97e7ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "model_input = Input(shape = (max_len,))\n",
        "z = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n",
        "                      input_length=max_len, trainable=False)(model_input)\n",
        "\n",
        "conv_blocks = []\n",
        "\n",
        "for sz in filter_sizes:\n",
        "    conv = Conv1D(filters = num_filters,\n",
        "                         kernel_size = sz,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z)\n",
        "    conv = GlobalMaxPooling1D()(conv)\n",
        "    conv = Flatten()(conv)\n",
        "    conv_blocks.append(conv)\n",
        "\n",
        "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
        "z = Dropout(drop)(z)\n",
        "model_output = Dense(len(label_idx)-1, activation='softmax')(z)\n",
        "\n",
        "model = Model(model_input, model_output)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 71)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 71, 100)      623700      input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_21 (Conv1D)              (None, 70, 512)      102912      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_22 (Conv1D)              (None, 69, 512)      154112      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_23 (Conv1D)              (None, 67, 512)      256512      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_21 (Global (None, 512)          0           conv1d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_22 (Global (None, 512)          0           conv1d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_23 (Global (None, 512)          0           conv1d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 512)          0           global_max_pooling1d_21[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_22 (Flatten)            (None, 512)          0           global_max_pooling1d_22[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_23 (Flatten)            (None, 512)          0           global_max_pooling1d_23[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 1536)         0           flatten_21[0][0]                 \n",
            "                                                                 flatten_22[0][0]                 \n",
            "                                                                 flatten_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 1536)         0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            1537        dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,138,773\n",
            "Trainable params: 515,073\n",
            "Non-trainable params: 623,700\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdgkAXY0fC-d",
        "outputId": "27c34008-2057-4265-80ec-4d233c2f7161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          validation_data = (X_val, y_val))"
      ],
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 2/10\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 3/10\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 4/10\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 5/10\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 6/10\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 7/10\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 8/10\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 9/10\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n",
            "Epoch 10/10\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - acc: 0.1325 - val_loss: 0.0000e+00 - val_acc: 0.1375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gvfi2oBtFEg"
      },
      "source": [
        "### 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W10Sa7IAiDJV"
      },
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = y_predicted.argmax(axis=-1) # 예측된 정수 시퀀스로 변환"
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3D6DOEKuBcv"
      },
      "source": [
        "y_predicted = idx_encode.inverse_transform(y_predicted) # 정수 시퀀스를 레이블에 해당하는 텍스트 시퀀스로 변환\n",
        "y_test = idx_encode.inverse_transform(y_test) # 정수 시퀀스를 레이블에 해당하는 텍스트 시퀀스로 변환"
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuo1qMfSuDwM",
        "outputId": "776aa368-0609-4d40-a39a-179128818097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "print('accuracy: ', sum(y_predicted == y_test) / len(y_test))\n",
        "print(\"Precision, Recall and F1-Score:\\n\\n\", classification_report(y_test, y_predicted))"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.8655913978494624\n",
            "Precision, Recall and F1-Score:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       483\n",
            "           1       0.00      0.00      0.00        75\n",
            "\n",
            "    accuracy                           0.87       558\n",
            "   macro avg       0.43      0.50      0.46       558\n",
            "weighted avg       0.75      0.87      0.80       558\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}