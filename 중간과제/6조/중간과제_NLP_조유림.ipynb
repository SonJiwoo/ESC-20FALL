{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "중간과제_NLP_조유림.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pj_P7en9ZQw"
      },
      "source": [
        "# Natural Language Processing Assignment: Spam Filter\n",
        "## Import necessary libs and datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EziGgWLOdu_b"
      },
      "source": [
        "#### 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoN1L0zOcd6H"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "import urllib.request"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEzpUVgH9VeV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\", filename=\"spam.csv\")\n",
        "data = pd.read_csv('spam.csv', encoding='latin1')\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o41ve7N99Yww",
        "outputId": "f1e926fa-ca06-4936-ad75-9ed797f80cd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#spam이 1\n",
        "del data['Unnamed: 2']\n",
        "del data['Unnamed: 3']\n",
        "del data['Unnamed: 4']\n",
        "\n",
        "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])\n",
        "data['text'] = data['v2']\n",
        "data['isSpam'] = data['v1']\n",
        "\n",
        "del data['v1'], data['v2']\n",
        "\n",
        "print(f'Data Shape: {data.shape}')\n",
        "# imbalanced data\n",
        "print(data['isSpam'].value_counts())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Shape: (5572, 2)\n",
            "0    4825\n",
            "1     747\n",
            "Name: isSpam, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9ftc8WM9jms"
      },
      "source": [
        "### 전처리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74S0S3y5dS8c"
      },
      "source": [
        "#### 특수기호, 영어 아닌 문자, 이중 space 제거, 대문자 소문자로 전환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5cFLugt9Yzg"
      },
      "source": [
        "import re\n",
        "\n",
        "pattern1 = '[^\\w\\s]' #특수기호 제거\n",
        "pattern2 = re.compile(r'\\s+') #이중 space 제거\n",
        "pattern3 = re.compile('[^a-zA-Z]') #영어가 아닌 문자 공백으로 대체 \n",
        "\n",
        "def preprocess(content)   :\n",
        "    content = re.sub(pattern1, ' ', content)\n",
        "    content = re.sub(pattern3, ' ', content)\n",
        "    content = re.sub(pattern2, ' ', content)\n",
        "    content = content.lower() #대문자 소문자로 전환\n",
        "        \n",
        "    return content"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bZN_7SU9Y20"
      },
      "source": [
        "data['text_n'] = data['text'].apply(lambda x: preprocess(x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcL-sSo79ujt"
      },
      "source": [
        "#### 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piQ9Zfuh-qDO",
        "outputId": "60c2000f-3210-4d05-e90e-1dcffcb7c988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrurKrOE9Y54",
        "outputId": "24b67942-bc64-4817-aff2-54b239e67958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# is that a the 등 불용어 제거\n",
        "from nltk.corpus import stopwords  \n",
        "stopwords.words('english')[:10]  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOcVxXWY9Y8h"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def stop_word_remove(content):\n",
        "    token = word_tokenize(content)\n",
        "    result = []\n",
        "    for w in token:\n",
        "        if w not in stop_words:\n",
        "            result.append(w)\n",
        "    text = ' '.join(result)\n",
        "    return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUhuWtwX9Y_U"
      },
      "source": [
        "data['text_n'] = data['text_n'].apply(lambda x: stop_word_remove(x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE5ElOYz98zi"
      },
      "source": [
        "#### glove pre-trained word vector 가져오기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1TrCZ4r6UmU"
      },
      "source": [
        "import numpy as np\n",
        "import gensim"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbIJnOd27aVU",
        "outputId": "a40197d0-1d0a-461d-a631-0b1a31241dd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd /content/drive/My Drive/esc"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/esc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dDI-hOFlPwB"
      },
      "source": [
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJUNDTwT7iFD",
        "outputId": "56470b20-e535-4aa8-bfdf-5c2f090c2a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(word2vec_model.vectors.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfvGu5cr86Oz",
        "outputId": "8c1142b0-d750-401b-8f44-e577b058c6c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "embedding_dict = dict()\n",
        "f = open(os.path.join('glove.6B.100d.txt'), encoding='utf-8')\n",
        "for line in f:\n",
        "    word_vector = line.split()\n",
        "    word = word_vector[0]\n",
        "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32') # 100개의 값을 가지는 array로 변환\n",
        "    embedding_dict[word] = word_vector_arr\n",
        "f.close()\n",
        "\n",
        "print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000개의 Embedding vector가 있습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyt_y6xd-9HO",
        "outputId": "796a39dd-4a4b-4499-f031-d00bf8f4506c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(embedding_dict['respectable'])\n",
        "print(len(embedding_dict['respectable']))\n",
        "#임베딩 된 벡터의 차원은 100차원 "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n",
            "  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n",
            "  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n",
            "  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n",
            " -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n",
            " -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n",
            " -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n",
            " -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n",
            " -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n",
            " -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n",
            " -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n",
            "  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n",
            "  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n",
            "  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n",
            " -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n",
            " -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n",
            " -0.21616   -0.19187   -0.032502   0.38025  ]\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXTGWadsi_sH"
      },
      "source": [
        "#### pre-trained vector에 없는 단어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ic4-CkBExQV"
      },
      "source": [
        "word_list=[]\n",
        "for i in data['text_n']:\n",
        "    i = word_tokenize(i)\n",
        "    word_list.extend(i)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SLSqe9mFrX1",
        "outputId": "8bd1f880-0dde-4e32-d386-2bc96d585bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(word_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHL6hxzPFspt",
        "outputId": "be12be0a-1180-4321-e269-ef97a3f7a9b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unique_word_list=[]\n",
        "for v in word_list:\n",
        "    if v not in unique_word_list:\n",
        "        unique_word_list.append(v)\n",
        "print(len(unique_word_list))\n",
        "# 7542개의 unique한 단어가 존재 "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoMPKerxjSRr"
      },
      "source": [
        "#우리가 토큰화 한 단어 들 중 glove에서 학습된 단어 벡터가 무엇인지 알아보자\n",
        "word_in_glove = []\n",
        "unknown = []\n",
        "for word in unique_word_list:\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        word_in_glove.append(word)\n",
        "    if embedding_vector is None:\n",
        "        unknown.append(word)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWDeSqV_jUCY",
        "outputId": "27948717-06e5-48e2-b5d7-9f3f2aa4416f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(word_in_glove)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EofbytYVro8H"
      },
      "source": [
        "def remove_word(sen):\n",
        "  word_list = []\n",
        "  tok = word_tokenize(sen)\n",
        "  for word in tok:\n",
        "    if word in word_in_glove:\n",
        "        word_list.append(word)\n",
        "  new_sen = \" \".join(word_list)\n",
        "  return new_sen"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Kj3oE6q2ER"
      },
      "source": [
        "data['text_n'] = data['text_n'].apply(lambda x: remove_word(x))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJAybNcn_S9C"
      },
      "source": [
        "#### X,y 데이터 처리\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHHYIYJwcAyQ"
      },
      "source": [
        "text_list = []\n",
        "for i in data.text_n:\n",
        "  text_list.append(str(i))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zuVVBhh_YuS"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_list)\n",
        "sequences = tokenizer.texts_to_sequences(text_list)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00X2dA6PHT8M",
        "outputId": "d4025031-b440-4726-fe41-94138d3b26ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#단어 인덱스\n",
        "word_index = tokenizer.word_index\n",
        "len(word_index)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9uBVgZGLwOu",
        "outputId": "07ae89df-44c0-4e35-a85b-d5673c7259f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_index"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'u': 1,\n",
              " 'call': 2,\n",
              " 'get': 3,\n",
              " 'ur': 4,\n",
              " 'gt': 5,\n",
              " 'lt': 6,\n",
              " 'ok': 7,\n",
              " 'free': 8,\n",
              " 'go': 9,\n",
              " 'know': 10,\n",
              " 'got': 11,\n",
              " 'like': 12,\n",
              " 'good': 13,\n",
              " 'day': 14,\n",
              " 'come': 15,\n",
              " 'time': 16,\n",
              " 'love': 17,\n",
              " 'send': 18,\n",
              " 'text': 19,\n",
              " 'want': 20,\n",
              " 'p': 21,\n",
              " 'txt': 22,\n",
              " 'one': 23,\n",
              " 'n': 24,\n",
              " 'going': 25,\n",
              " 'r': 26,\n",
              " 'need': 27,\n",
              " 'home': 28,\n",
              " 'stop': 29,\n",
              " 'lor': 30,\n",
              " 'k': 31,\n",
              " 'today': 32,\n",
              " 'sorry': 33,\n",
              " 'see': 34,\n",
              " 'still': 35,\n",
              " 'back': 36,\n",
              " 'da': 37,\n",
              " 'reply': 38,\n",
              " 'mobile': 39,\n",
              " 'dont': 40,\n",
              " 'take': 41,\n",
              " 'tell': 42,\n",
              " 'hi': 43,\n",
              " 'new': 44,\n",
              " 'later': 45,\n",
              " 'pls': 46,\n",
              " 'please': 47,\n",
              " 'think': 48,\n",
              " 'phone': 49,\n",
              " 'c': 50,\n",
              " 'week': 51,\n",
              " 'dear': 52,\n",
              " 'well': 53,\n",
              " 'much': 54,\n",
              " 'great': 55,\n",
              " 'night': 56,\n",
              " 'oh': 57,\n",
              " 'claim': 58,\n",
              " 'msg': 59,\n",
              " 'hope': 60,\n",
              " 'hey': 61,\n",
              " 'na': 62,\n",
              " 'b': 63,\n",
              " 'wat': 64,\n",
              " 'happy': 65,\n",
              " 'yes': 66,\n",
              " 'way': 67,\n",
              " 'make': 68,\n",
              " 'give': 69,\n",
              " 'www': 70,\n",
              " 'work': 71,\n",
              " 'e': 72,\n",
              " 'number': 73,\n",
              " 'message': 74,\n",
              " 'wan': 75,\n",
              " 'prize': 76,\n",
              " 'tomorrow': 77,\n",
              " 'say': 78,\n",
              " 'right': 79,\n",
              " 'already': 80,\n",
              " 'ask': 81,\n",
              " 'cash': 82,\n",
              " 'said': 83,\n",
              " 'yeah': 84,\n",
              " 'really': 85,\n",
              " 'amp': 86,\n",
              " 'im': 87,\n",
              " 'win': 88,\n",
              " 'meet': 89,\n",
              " 'find': 90,\n",
              " 'life': 91,\n",
              " 'let': 92,\n",
              " 'morning': 93,\n",
              " 'babe': 94,\n",
              " 'thanks': 95,\n",
              " 'last': 96,\n",
              " 'miss': 97,\n",
              " 'com': 98,\n",
              " 'would': 99,\n",
              " 'cos': 100,\n",
              " 'uk': 101,\n",
              " 'lol': 102,\n",
              " 'anything': 103,\n",
              " 'nokia': 104,\n",
              " 'also': 105,\n",
              " 'every': 106,\n",
              " 'sure': 107,\n",
              " 'pick': 108,\n",
              " 'care': 109,\n",
              " 'urgent': 110,\n",
              " 'min': 111,\n",
              " 'sent': 112,\n",
              " 'something': 113,\n",
              " 'keep': 114,\n",
              " 'contact': 115,\n",
              " 'us': 116,\n",
              " 'buy': 117,\n",
              " 'wait': 118,\n",
              " 'x': 119,\n",
              " 'cant': 120,\n",
              " 'first': 121,\n",
              " 'w': 122,\n",
              " 'thing': 123,\n",
              " 'even': 124,\n",
              " 'help': 125,\n",
              " 'next': 126,\n",
              " 'feel': 127,\n",
              " 'nice': 128,\n",
              " 'someone': 129,\n",
              " 'went': 130,\n",
              " 'box': 131,\n",
              " 'around': 132,\n",
              " 'soon': 133,\n",
              " 'could': 134,\n",
              " 'place': 135,\n",
              " 'money': 136,\n",
              " 'service': 137,\n",
              " 'tone': 138,\n",
              " 'per': 139,\n",
              " 'gon': 140,\n",
              " 'tonight': 141,\n",
              " 'late': 142,\n",
              " 'chat': 143,\n",
              " 'mins': 144,\n",
              " 'many': 145,\n",
              " 'customer': 146,\n",
              " 'sms': 147,\n",
              " 'ya': 148,\n",
              " 'sleep': 149,\n",
              " 'always': 150,\n",
              " 'leave': 151,\n",
              " 'co': 152,\n",
              " 'dun': 153,\n",
              " 'friends': 154,\n",
              " 'v': 155,\n",
              " 'pm': 156,\n",
              " 'gud': 157,\n",
              " 'st': 158,\n",
              " 'name': 159,\n",
              " 'things': 160,\n",
              " 'told': 161,\n",
              " 'wish': 162,\n",
              " 'hello': 163,\n",
              " 'waiting': 164,\n",
              " 'fine': 165,\n",
              " 'friend': 166,\n",
              " 'special': 167,\n",
              " 'haha': 168,\n",
              " 'coming': 169,\n",
              " 'may': 170,\n",
              " 'getting': 171,\n",
              " 'done': 172,\n",
              " 'year': 173,\n",
              " 'guaranteed': 174,\n",
              " 'yet': 175,\n",
              " 'people': 176,\n",
              " 'thk': 177,\n",
              " 'days': 178,\n",
              " 'use': 179,\n",
              " 'try': 180,\n",
              " 'best': 181,\n",
              " 'ppm': 182,\n",
              " 'heart': 183,\n",
              " 'thought': 184,\n",
              " 'holiday': 185,\n",
              " 'th': 186,\n",
              " 'stuff': 187,\n",
              " 'lunch': 188,\n",
              " 'live': 189,\n",
              " 'man': 190,\n",
              " 'god': 191,\n",
              " 'talk': 192,\n",
              " 'class': 193,\n",
              " 'smile': 194,\n",
              " 'draw': 195,\n",
              " 'cs': 196,\n",
              " 'yup': 197,\n",
              " 'trying': 198,\n",
              " 'bit': 199,\n",
              " 'never': 200,\n",
              " 'meeting': 201,\n",
              " 'thats': 202,\n",
              " 'job': 203,\n",
              " 'better': 204,\n",
              " 'house': 205,\n",
              " 'person': 206,\n",
              " 'line': 207,\n",
              " 'finish': 208,\n",
              " 'end': 209,\n",
              " 'cool': 210,\n",
              " 'long': 211,\n",
              " 'ill': 212,\n",
              " 'ready': 213,\n",
              " 'cost': 214,\n",
              " 'car': 215,\n",
              " 'dat': 216,\n",
              " 'mind': 217,\n",
              " 'half': 218,\n",
              " 'real': 219,\n",
              " 'account': 220,\n",
              " 'enjoy': 221,\n",
              " 'latest': 222,\n",
              " 'month': 223,\n",
              " 'play': 224,\n",
              " 'check': 225,\n",
              " 'yo': 226,\n",
              " 'wk': 227,\n",
              " 'sir': 228,\n",
              " 'chance': 229,\n",
              " 'world': 230,\n",
              " 'lar': 231,\n",
              " 'receive': 232,\n",
              " 'word': 233,\n",
              " 'camera': 234,\n",
              " 'eat': 235,\n",
              " 'awarded': 236,\n",
              " 'nothing': 237,\n",
              " 'guess': 238,\n",
              " 'lot': 239,\n",
              " 'g': 240,\n",
              " 'problem': 241,\n",
              " 'another': 242,\n",
              " 'liao': 243,\n",
              " 'big': 244,\n",
              " 'shit': 245,\n",
              " 'dinner': 246,\n",
              " 'ah': 247,\n",
              " 'birthday': 248,\n",
              " 'shows': 249,\n",
              " 'girl': 250,\n",
              " 'bt': 251,\n",
              " 'guys': 252,\n",
              " 'start': 253,\n",
              " 'sweet': 254,\n",
              " 'hrs': 255,\n",
              " 'luv': 256,\n",
              " 'jus': 257,\n",
              " 'po': 258,\n",
              " 'might': 259,\n",
              " 'ever': 260,\n",
              " 'quite': 261,\n",
              " 'xxx': 262,\n",
              " 'watching': 263,\n",
              " 'room': 264,\n",
              " 'landline': 265,\n",
              " 'offer': 266,\n",
              " 'video': 267,\n",
              " 'early': 268,\n",
              " 'speak': 269,\n",
              " 'nd': 270,\n",
              " 'weekend': 271,\n",
              " 'calls': 272,\n",
              " 'pa': 273,\n",
              " 'bed': 274,\n",
              " 'tv': 275,\n",
              " 'called': 276,\n",
              " 'watch': 277,\n",
              " 'probably': 278,\n",
              " 'rate': 279,\n",
              " 'apply': 280,\n",
              " 'fun': 281,\n",
              " 'wont': 282,\n",
              " 'remember': 283,\n",
              " 'ringtone': 284,\n",
              " 'maybe': 285,\n",
              " 'hear': 286,\n",
              " 'forgot': 287,\n",
              " 'boy': 288,\n",
              " 'nite': 289,\n",
              " 'plan': 290,\n",
              " 'shall': 291,\n",
              " 'two': 292,\n",
              " 'minutes': 293,\n",
              " 'sat': 294,\n",
              " 'actually': 295,\n",
              " 'den': 296,\n",
              " 'bad': 297,\n",
              " 'princess': 298,\n",
              " 'code': 299,\n",
              " 'pay': 300,\n",
              " 'left': 301,\n",
              " 'look': 302,\n",
              " 'part': 303,\n",
              " 'easy': 304,\n",
              " 'reach': 305,\n",
              " 'shopping': 306,\n",
              " 'baby': 307,\n",
              " 'dunno': 308,\n",
              " 'orange': 309,\n",
              " 'office': 310,\n",
              " 'kiss': 311,\n",
              " 'bus': 312,\n",
              " 'dis': 313,\n",
              " 'award': 314,\n",
              " 'age': 315,\n",
              " 'little': 316,\n",
              " 'leh': 317,\n",
              " 'face': 318,\n",
              " 'didnt': 319,\n",
              " 'hour': 320,\n",
              " 'tones': 321,\n",
              " 'network': 322,\n",
              " 'selected': 323,\n",
              " 'enough': 324,\n",
              " 'thank': 325,\n",
              " 'xx': 326,\n",
              " 'looking': 327,\n",
              " 'anyway': 328,\n",
              " 'working': 329,\n",
              " 'everything': 330,\n",
              " 'true': 331,\n",
              " 'made': 332,\n",
              " 'put': 333,\n",
              " 'fuck': 334,\n",
              " 'wife': 335,\n",
              " 'dad': 336,\n",
              " 'entry': 337,\n",
              " 'afternoon': 338,\n",
              " 'without': 339,\n",
              " 'missing': 340,\n",
              " 'years': 341,\n",
              " 'tmr': 342,\n",
              " 'evening': 343,\n",
              " 'collect': 344,\n",
              " 'asked': 345,\n",
              " 'gift': 346,\n",
              " 'texts': 347,\n",
              " 'town': 348,\n",
              " 'wif': 349,\n",
              " 'though': 350,\n",
              " 'valid': 351,\n",
              " 'times': 352,\n",
              " 'since': 353,\n",
              " 'came': 354,\n",
              " 'okay': 355,\n",
              " 'says': 356,\n",
              " 'must': 357,\n",
              " 'school': 358,\n",
              " 'join': 359,\n",
              " 'mail': 360,\n",
              " 'sexy': 361,\n",
              " 'xmas': 362,\n",
              " 'details': 363,\n",
              " 'goes': 364,\n",
              " 'update': 365,\n",
              " 'wanted': 366,\n",
              " 'missed': 367,\n",
              " 'pain': 368,\n",
              " 'means': 369,\n",
              " 'abt': 370,\n",
              " 'price': 371,\n",
              " 'til': 372,\n",
              " 'able': 373,\n",
              " 'hav': 374,\n",
              " 'important': 375,\n",
              " 'wake': 376,\n",
              " 'guy': 377,\n",
              " 'wot': 378,\n",
              " 'bring': 379,\n",
              " 'collection': 380,\n",
              " 'messages': 381,\n",
              " 'mob': 382,\n",
              " 'show': 383,\n",
              " 'juz': 384,\n",
              " 'decimal': 385,\n",
              " 'plz': 386,\n",
              " 'de': 387,\n",
              " 'away': 388,\n",
              " 'plus': 389,\n",
              " 'alright': 390,\n",
              " 'till': 391,\n",
              " 'saw': 392,\n",
              " 'yesterday': 393,\n",
              " 'hair': 394,\n",
              " 'wen': 395,\n",
              " 'havent': 396,\n",
              " 'else': 397,\n",
              " 'worry': 398,\n",
              " 'music': 399,\n",
              " 'weekly': 400,\n",
              " 'attempt': 401,\n",
              " 'colour': 402,\n",
              " 'net': 403,\n",
              " 'words': 404,\n",
              " 'double': 405,\n",
              " 'run': 406,\n",
              " 'making': 407,\n",
              " 'food': 408,\n",
              " 'haf': 409,\n",
              " 'id': 410,\n",
              " 'oso': 411,\n",
              " 'shop': 412,\n",
              " 'book': 413,\n",
              " 'dude': 414,\n",
              " 'stay': 415,\n",
              " 'bored': 416,\n",
              " 'online': 417,\n",
              " 'makes': 418,\n",
              " 'goin': 419,\n",
              " 'lei': 420,\n",
              " 'question': 421,\n",
              " 'hours': 422,\n",
              " 'national': 423,\n",
              " 'ard': 424,\n",
              " 'tried': 425,\n",
              " 'delivery': 426,\n",
              " 'driving': 427,\n",
              " 'test': 428,\n",
              " 'address': 429,\n",
              " 'answer': 430,\n",
              " 'top': 431,\n",
              " 'coz': 432,\n",
              " 'gr': 433,\n",
              " 'hot': 434,\n",
              " 'club': 435,\n",
              " 'hurt': 436,\n",
              " 'friendship': 437,\n",
              " 'j': 438,\n",
              " 'change': 439,\n",
              " 'feeling': 440,\n",
              " 'either': 441,\n",
              " 'sch': 442,\n",
              " 'family': 443,\n",
              " 'date': 444,\n",
              " 'http': 445,\n",
              " 'bonus': 446,\n",
              " 'trip': 447,\n",
              " 'comes': 448,\n",
              " 'movie': 449,\n",
              " 'busy': 450,\n",
              " 'todays': 451,\n",
              " 'nt': 452,\n",
              " 'order': 453,\n",
              " 'believe': 454,\n",
              " 'vouchers': 455,\n",
              " 'wid': 456,\n",
              " 'full': 457,\n",
              " 'calling': 458,\n",
              " 'tot': 459,\n",
              " 'beautiful': 460,\n",
              " 'sae': 461,\n",
              " 'lose': 462,\n",
              " 'game': 463,\n",
              " 'together': 464,\n",
              " 'wants': 465,\n",
              " 'sad': 466,\n",
              " 'brother': 467,\n",
              " 'set': 468,\n",
              " 'info': 469,\n",
              " 'smiling': 470,\n",
              " 'mean': 471,\n",
              " 'old': 472,\n",
              " 'points': 473,\n",
              " 'leaving': 474,\n",
              " 'story': 475,\n",
              " 'sleeping': 476,\n",
              " 'noe': 477,\n",
              " 'happen': 478,\n",
              " 'ring': 479,\n",
              " 'charge': 480,\n",
              " 'games': 481,\n",
              " 'huh': 482,\n",
              " 'poly': 483,\n",
              " 'eve': 484,\n",
              " 'saying': 485,\n",
              " 'drive': 486,\n",
              " 'await': 487,\n",
              " 'dreams': 488,\n",
              " 'pounds': 489,\n",
              " 'hl': 490,\n",
              " 'news': 491,\n",
              " 'aft': 492,\n",
              " 'tomo': 493,\n",
              " 'congrats': 494,\n",
              " 'took': 495,\n",
              " 'finished': 496,\n",
              " 'ta': 497,\n",
              " 'started': 498,\n",
              " 'private': 499,\n",
              " 'awesome': 500,\n",
              " 'minute': 501,\n",
              " 'walk': 502,\n",
              " 'okie': 503,\n",
              " 'post': 504,\n",
              " 'suite': 505,\n",
              " 'row': 506,\n",
              " 'head': 507,\n",
              " 'thinking': 508,\n",
              " 'simple': 509,\n",
              " 'pics': 510,\n",
              " 'mum': 511,\n",
              " 'email': 512,\n",
              " 'rite': 513,\n",
              " 'pic': 514,\n",
              " 'available': 515,\n",
              " 'final': 516,\n",
              " 'tho': 517,\n",
              " 'forget': 518,\n",
              " 'second': 519,\n",
              " 'close': 520,\n",
              " 'cause': 521,\n",
              " 'services': 522,\n",
              " 'taking': 523,\n",
              " 'everyone': 524,\n",
              " 'wil': 525,\n",
              " 'angry': 526,\n",
              " 'unsubscribe': 527,\n",
              " 'lets': 528,\n",
              " 'drink': 529,\n",
              " 'land': 530,\n",
              " 'gd': 531,\n",
              " 'mine': 532,\n",
              " 'neva': 533,\n",
              " 'pub': 534,\n",
              " 'drop': 535,\n",
              " 'auction': 536,\n",
              " 'lesson': 537,\n",
              " 'lucky': 538,\n",
              " 'search': 539,\n",
              " 'statement': 540,\n",
              " 'expires': 541,\n",
              " 'open': 542,\n",
              " 'whats': 543,\n",
              " 'lots': 544,\n",
              " 'parents': 545,\n",
              " 'carlos': 546,\n",
              " 'smoke': 547,\n",
              " 'worth': 548,\n",
              " 'sis': 549,\n",
              " 'touch': 550,\n",
              " 'found': 551,\n",
              " 'break': 552,\n",
              " 'sounds': 553,\n",
              " 'company': 554,\n",
              " 'choose': 555,\n",
              " 'card': 556,\n",
              " 'sister': 557,\n",
              " 'dating': 558,\n",
              " 'opt': 559,\n",
              " 'whatever': 560,\n",
              " 'voucher': 561,\n",
              " 'sun': 562,\n",
              " 'anyone': 563,\n",
              " 'loving': 564,\n",
              " 'alone': 565,\n",
              " 'treat': 566,\n",
              " 'winner': 567,\n",
              " 'ha': 568,\n",
              " 'smth': 569,\n",
              " 'mom': 570,\n",
              " 'saturday': 571,\n",
              " 'decided': 572,\n",
              " 'girls': 573,\n",
              " 'prob': 574,\n",
              " 'gone': 575,\n",
              " 'happened': 576,\n",
              " 'identifier': 577,\n",
              " 'yr': 578,\n",
              " 'type': 579,\n",
              " 'ltd': 580,\n",
              " 'hard': 581,\n",
              " 'f': 582,\n",
              " 'needs': 583,\n",
              " 'college': 584,\n",
              " 'rs': 585,\n",
              " 'gbp': 586,\n",
              " 'takes': 587,\n",
              " 'anytime': 588,\n",
              " 'far': 589,\n",
              " 'lands': 590,\n",
              " 'kind': 591,\n",
              " 'visit': 592,\n",
              " 'fast': 593,\n",
              " 'crazy': 594,\n",
              " 'wonderful': 595,\n",
              " 'camcorder': 596,\n",
              " 'used': 597,\n",
              " 'hit': 598,\n",
              " 'operator': 599,\n",
              " 'friday': 600,\n",
              " 'quiz': 601,\n",
              " 'player': 602,\n",
              " 'hand': 603,\n",
              " 'content': 604,\n",
              " 'wit': 605,\n",
              " 'finally': 606,\n",
              " 'darlin': 607,\n",
              " 'goodmorning': 608,\n",
              " 'secret': 609,\n",
              " 'tel': 610,\n",
              " 'congratulations': 611,\n",
              " 'read': 612,\n",
              " 'light': 613,\n",
              " 'bout': 614,\n",
              " 'fucking': 615,\n",
              " 'nope': 616,\n",
              " 'outside': 617,\n",
              " 'fri': 618,\n",
              " 'pretty': 619,\n",
              " 'sea': 620,\n",
              " 'weeks': 621,\n",
              " 'lovely': 622,\n",
              " 'mates': 623,\n",
              " 'wrong': 624,\n",
              " 'least': 625,\n",
              " 'party': 626,\n",
              " 'chennai': 627,\n",
              " 'hows': 628,\n",
              " 'sunday': 629,\n",
              " 'credit': 630,\n",
              " 'hungry': 631,\n",
              " 'seeing': 632,\n",
              " 'telling': 633,\n",
              " 'whole': 634,\n",
              " 'hmm': 635,\n",
              " 'mu': 636,\n",
              " 'ni': 637,\n",
              " 'fancy': 638,\n",
              " 'bank': 639,\n",
              " 'log': 640,\n",
              " 'course': 641,\n",
              " 'tc': 642,\n",
              " 'thinks': 643,\n",
              " 'case': 644,\n",
              " 'meant': 645,\n",
              " 'fr': 646,\n",
              " 'hold': 647,\n",
              " 'unlimited': 648,\n",
              " 'blue': 649,\n",
              " 'fone': 650,\n",
              " 'l': 651,\n",
              " 'jay': 652,\n",
              " 'project': 653,\n",
              " 'reason': 654,\n",
              " 'ten': 655,\n",
              " 'welcome': 656,\n",
              " 'cum': 657,\n",
              " 'frm': 658,\n",
              " 'offers': 659,\n",
              " 'listen': 660,\n",
              " 'snow': 661,\n",
              " 'mate': 662,\n",
              " 'earlier': 663,\n",
              " 'point': 664,\n",
              " 'press': 665,\n",
              " 'valued': 666,\n",
              " 'months': 667,\n",
              " 'mobiles': 668,\n",
              " 'eh': 669,\n",
              " 'almost': 670,\n",
              " 'etc': 671,\n",
              " 'cut': 672,\n",
              " 'hee': 673,\n",
              " 'download': 674,\n",
              " 'mah': 675,\n",
              " 'felt': 676,\n",
              " 'invited': 677,\n",
              " 'caller': 678,\n",
              " 'numbers': 679,\n",
              " 'tired': 680,\n",
              " 'hmmm': 681,\n",
              " 'mr': 682,\n",
              " 'balance': 683,\n",
              " 'march': 684,\n",
              " 'side': 685,\n",
              " 'dnt': 686,\n",
              " 'stupid': 687,\n",
              " 'die': 688,\n",
              " 'lost': 689,\n",
              " 'christmas': 690,\n",
              " 'reading': 691,\n",
              " 'ago': 692,\n",
              " 'currently': 693,\n",
              " 'motorola': 694,\n",
              " 'talking': 695,\n",
              " 'couple': 696,\n",
              " 'phones': 697,\n",
              " 'ass': 698,\n",
              " 'india': 699,\n",
              " 'sk': 700,\n",
              " 'park': 701,\n",
              " 'within': 702,\n",
              " 'un': 703,\n",
              " 'yar': 704,\n",
              " 'happiness': 705,\n",
              " 'area': 706,\n",
              " 'sex': 707,\n",
              " 'understand': 708,\n",
              " 'yrs': 709,\n",
              " 'support': 710,\n",
              " 'luck': 711,\n",
              " 'enter': 712,\n",
              " 'john': 713,\n",
              " 'gas': 714,\n",
              " 'father': 715,\n",
              " 'comp': 716,\n",
              " 'charged': 717,\n",
              " 'confirm': 718,\n",
              " 'wow': 719,\n",
              " 'ac': 720,\n",
              " 'red': 721,\n",
              " 'correct': 722,\n",
              " 'pass': 723,\n",
              " 'song': 724,\n",
              " 'complimentary': 725,\n",
              " 'computer': 726,\n",
              " 'uncle': 727,\n",
              " 'sending': 728,\n",
              " 'direct': 729,\n",
              " 'joy': 730,\n",
              " 'semester': 731,\n",
              " 'reveal': 732,\n",
              " 'laptop': 733,\n",
              " 'questions': 734,\n",
              " 'swing': 735,\n",
              " 'ends': 736,\n",
              " 'via': 737,\n",
              " 'ish': 738,\n",
              " 'met': 739,\n",
              " 'seen': 740,\n",
              " 'rental': 741,\n",
              " 'supposed': 742,\n",
              " 'nyt': 743,\n",
              " 'ipod': 744,\n",
              " 'redeemed': 745,\n",
              " 'max': 746,\n",
              " 'gym': 747,\n",
              " 'darren': 748,\n",
              " 'sound': 749,\n",
              " 'xy': 750,\n",
              " 'ans': 751,\n",
              " 'picking': 752,\n",
              " 'ugh': 753,\n",
              " 'extra': 754,\n",
              " 'knew': 755,\n",
              " 'heard': 756,\n",
              " 'information': 757,\n",
              " 'surprise': 758,\n",
              " 'grins': 759,\n",
              " 'gal': 760,\n",
              " 'difficult': 761,\n",
              " 'std': 762,\n",
              " 'usf': 763,\n",
              " 'reward': 764,\n",
              " 'wap': 765,\n",
              " 'eg': 766,\n",
              " 'comin': 767,\n",
              " 'abiola': 768,\n",
              " 'crave': 769,\n",
              " 'gets': 770,\n",
              " 'move': 771,\n",
              " 'checking': 772,\n",
              " 'loads': 773,\n",
              " 'shower': 774,\n",
              " 'entered': 775,\n",
              " 'match': 776,\n",
              " 'dogging': 777,\n",
              " 'lovable': 778,\n",
              " 'wine': 779,\n",
              " 'dream': 780,\n",
              " 'safe': 781,\n",
              " 'muz': 782,\n",
              " 'bath': 783,\n",
              " 'orchard': 784,\n",
              " 'kate': 785,\n",
              " 'exam': 786,\n",
              " 'wana': 787,\n",
              " 'hmv': 788,\n",
              " 'somebody': 789,\n",
              " 'rest': 790,\n",
              " 'plans': 791,\n",
              " 'small': 792,\n",
              " 'ex': 793,\n",
              " 'hg': 794,\n",
              " 'discount': 795,\n",
              " 'slow': 796,\n",
              " 'rock': 797,\n",
              " 'asking': 798,\n",
              " 'remove': 799,\n",
              " 'terms': 800,\n",
              " 'monday': 801,\n",
              " 'blood': 802,\n",
              " 'clean': 803,\n",
              " 'ts': 804,\n",
              " 'paper': 805,\n",
              " 'store': 806,\n",
              " 'wonder': 807,\n",
              " 'whenever': 808,\n",
              " 'sort': 809,\n",
              " 'asap': 810,\n",
              " 'truth': 811,\n",
              " 'feels': 812,\n",
              " 'loved': 813,\n",
              " 'slowly': 814,\n",
              " 'gn': 815,\n",
              " 'police': 816,\n",
              " 'la': 817,\n",
              " 'nah': 818,\n",
              " 'link': 819,\n",
              " 'england': 820,\n",
              " 'worried': 821,\n",
              " 'knows': 822,\n",
              " 'oops': 823,\n",
              " 'hospital': 824,\n",
              " 'reached': 825,\n",
              " 'save': 826,\n",
              " 'tickets': 827,\n",
              " 'il': 828,\n",
              " 'representative': 829,\n",
              " 'gave': 830,\n",
              " 'rates': 831,\n",
              " 'del': 832,\n",
              " 'sony': 833,\n",
              " 'pray': 834,\n",
              " 'spend': 835,\n",
              " 'bathe': 836,\n",
              " 'bill': 837,\n",
              " 'study': 838,\n",
              " 'admirer': 839,\n",
              " 'deep': 840,\n",
              " 'leaves': 841,\n",
              " 'usual': 842,\n",
              " 'ge': 843,\n",
              " 'tonite': 844,\n",
              " 'somewhere': 845,\n",
              " 'normal': 846,\n",
              " 'merry': 847,\n",
              " 'pete': 848,\n",
              " 'immediately': 849,\n",
              " 'figure': 850,\n",
              " 'moment': 851,\n",
              " 'woke': 852,\n",
              " 'mm': 853,\n",
              " 'yep': 854,\n",
              " 'voice': 855,\n",
              " 'ldn': 856,\n",
              " 'wc': 857,\n",
              " 'booked': 858,\n",
              " 'different': 859,\n",
              " 'water': 860,\n",
              " 'less': 861,\n",
              " 'sub': 862,\n",
              " 'hoping': 863,\n",
              " 'across': 864,\n",
              " 'warm': 865,\n",
              " 'cheap': 866,\n",
              " 'kids': 867,\n",
              " 'em': 868,\n",
              " 'drugs': 869,\n",
              " 'laugh': 870,\n",
              " 'fantastic': 871,\n",
              " 'sell': 872,\n",
              " 'glad': 873,\n",
              " 'wishing': 874,\n",
              " 'gettin': 875,\n",
              " 'poor': 876,\n",
              " 'otherwise': 877,\n",
              " 'ntt': 878,\n",
              " 'cr': 879,\n",
              " 'rd': 880,\n",
              " 'convey': 881,\n",
              " 'film': 882,\n",
              " 'energy': 883,\n",
              " 'nobody': 884,\n",
              " 'ringtones': 885,\n",
              " 'bb': 886,\n",
              " 'write': 887,\n",
              " 'fact': 888,\n",
              " 'doin': 889,\n",
              " 'hw': 890,\n",
              " 'empty': 891,\n",
              " 'cup': 892,\n",
              " 'copy': 893,\n",
              " 'promise': 894,\n",
              " 'seriously': 895,\n",
              " 'sick': 896,\n",
              " 'catch': 897,\n",
              " 'decide': 898,\n",
              " 'ice': 899,\n",
              " 'bx': 900,\n",
              " 'ip': 901,\n",
              " 'situation': 902,\n",
              " 'forever': 903,\n",
              " 'short': 904,\n",
              " 'rain': 905,\n",
              " 'men': 906,\n",
              " 'boss': 907,\n",
              " 'specially': 908,\n",
              " 'ending': 909,\n",
              " 'buying': 910,\n",
              " 'sunshine': 911,\n",
              " 'lazy': 912,\n",
              " 'lect': 913,\n",
              " 'completely': 914,\n",
              " 'staying': 915,\n",
              " 'doesnt': 916,\n",
              " 'especially': 917,\n",
              " 'studying': 918,\n",
              " 'trust': 919,\n",
              " 'using': 920,\n",
              " 'deal': 921,\n",
              " 'dead': 922,\n",
              " 'mrt': 923,\n",
              " 'ive': 924,\n",
              " 'lessons': 925,\n",
              " 'street': 926,\n",
              " 'goodnight': 927,\n",
              " 'cd': 928,\n",
              " 'lover': 929,\n",
              " 'disturb': 930,\n",
              " 'credits': 931,\n",
              " 'worries': 932,\n",
              " 'unless': 933,\n",
              " 'accept': 934,\n",
              " 'access': 935,\n",
              " 'valentines': 936,\n",
              " 'weed': 937,\n",
              " 'bluetooth': 938,\n",
              " 'brings': 939,\n",
              " 'al': 940,\n",
              " 'none': 941,\n",
              " 'starts': 942,\n",
              " 'kinda': 943,\n",
              " 'loan': 944,\n",
              " 'meh': 945,\n",
              " 'near': 946,\n",
              " 'rent': 947,\n",
              " 'silent': 948,\n",
              " 'children': 949,\n",
              " 'pound': 950,\n",
              " 'train': 951,\n",
              " 'noon': 952,\n",
              " 'valentine': 953,\n",
              " 'forwarded': 954,\n",
              " 'pc': 955,\n",
              " 'starting': 956,\n",
              " 'ho': 957,\n",
              " 'bold': 958,\n",
              " 'seems': 959,\n",
              " 'eyes': 960,\n",
              " 'possible': 961,\n",
              " 'summer': 962,\n",
              " 'norm': 963,\n",
              " 'ones': 964,\n",
              " 'charity': 965,\n",
              " 'tampa': 966,\n",
              " 'user': 967,\n",
              " 'hiya': 968,\n",
              " 'digital': 969,\n",
              " 'doctor': 970,\n",
              " 'mon': 971,\n",
              " 'mode': 972,\n",
              " 'wondering': 973,\n",
              " 'others': 974,\n",
              " 'tht': 975,\n",
              " 'reaching': 976,\n",
              " 'moral': 977,\n",
              " 'excellent': 978,\n",
              " 'thinkin': 979,\n",
              " 'sitting': 980,\n",
              " 'flag': 981,\n",
              " 'colleagues': 982,\n",
              " 'sofa': 983,\n",
              " 'request': 984,\n",
              " 'entitled': 985,\n",
              " 'anymore': 986,\n",
              " 'mark': 987,\n",
              " 'pizza': 988,\n",
              " 'cheers': 989,\n",
              " 'quick': 990,\n",
              " 'replying': 991,\n",
              " 'nigeria': 992,\n",
              " 'cinema': 993,\n",
              " 'stand': 994,\n",
              " 'spent': 995,\n",
              " 'trouble': 996,\n",
              " 'hurts': 997,\n",
              " 'loves': 998,\n",
              " 'planning': 999,\n",
              " 'ave': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ef0nwGlcu_B",
        "outputId": "2ad90d40-cf76-4815-c7f9-32c7c6463dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#문장에 있는 최대 단어 수 \n",
        "max_len=max(len(word_tokenize(l)) for l in data.text_n)\n",
        "max_len"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlLDsGhh_bZD"
      },
      "source": [
        "# 73차원에 맞춰서 단어수가 그 이하인 경우 제로패딩\n",
        "X = pad_sequences(sequences, maxlen = max_len)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muOWg_EPgUDV"
      },
      "source": [
        "idx_encode = preprocessing.LabelEncoder()\n",
        "idx_encode.fit(data.isSpam)\n",
        "\n",
        "y = idx_encode.transform(data.isSpam)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUZr_RD3hMRL",
        "outputId": "6e3cc6f6-c820-4351-a9d2-1a264e9ea925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X[0])\n",
        "print(y[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    9 3446  664  594  515 1090   24   55  230  817   72 2409 1091\n",
            "   11 3447   64]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YadRoJ6_iXl"
      },
      "source": [
        "#### 임베딩 테이블 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNrmLnuvANcR"
      },
      "source": [
        "embedding_dim = 100\n",
        "vocab_size=len(word_index)+1 \n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eeZfQG1Asu-"
      },
      "source": [
        "for word, i in word_index.items():\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfzdJNMUL8Cw",
        "outputId": "484a8b72-9c2f-4f8b-a5ff-12139cedab36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embedding_matrix[1]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.031087  ,  0.22155   ,  0.44494   ,  0.92176002, -0.18663   ,\n",
              "        0.069117  ,  0.32929999,  0.26914999,  0.15561999,  0.31308001,\n",
              "        0.61151999, -0.11215   ,  0.21906   ,  0.49480999,  0.087445  ,\n",
              "        0.09159   , -0.14940999, -0.003524  ,  0.035123  ,  0.42403001,\n",
              "        1.30929995,  0.38262999, -0.40788001,  0.16399001, -0.40562001,\n",
              "        0.87825   ,  0.38619   ,  0.45629999,  0.90609002, -0.48334   ,\n",
              "        0.30579999,  1.16970003,  0.22698   ,  0.40321001, -0.19317   ,\n",
              "        0.46834999,  0.50217003,  1.2198    ,  0.11228   , -0.70321   ,\n",
              "        0.16696   , -0.13545001,  0.14074001, -0.50954002,  0.10954   ,\n",
              "        0.070928  , -0.43888   ,  0.57235003,  0.28055   ,  0.44428   ,\n",
              "       -0.39781001,  0.28689   ,  0.40588   ,  0.25378999,  0.022166  ,\n",
              "       -0.77767998, -0.28907999,  0.52274001,  1.07459998, -0.18212   ,\n",
              "       -1.13880002, -0.55752999, -0.78219998, -0.31826001,  0.43900999,\n",
              "        0.71710998,  0.70670998,  0.84200001,  0.014151  ,  0.37457001,\n",
              "        0.26225001,  0.47146001,  0.19087   , -1.09599996,  0.35595   ,\n",
              "        0.25325999, -0.086234  ,  0.69395   , -0.0077498 , -0.35523999,\n",
              "       -0.11673   , -1.53509998, -0.22939   , -0.19140001, -0.94134998,\n",
              "        0.33092001,  0.35075   , -1.62269998,  0.42651001, -0.10422   ,\n",
              "       -0.10879   ,  0.81115001, -0.26945999,  0.47198999,  0.0848    ,\n",
              "       -0.70240998,  0.18598001, -0.67097002,  0.24698   , -0.62001002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxZviG1lWBQd"
      },
      "source": [
        "#### train/test data 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVcUmfftWJlc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,\n",
        "                                                   stratify=y, test_size=0.1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi06_QYPg9MT",
        "outputId": "d97d75bc-4b86-49df-b0e9-1e8b8c8c98e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5014, 73)\n",
            "(5014,)\n",
            "(558, 73)\n",
            "(558,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn1xePRztVBQ"
      },
      "source": [
        "#random state로 데이터가 고정되어 있어서 train data를 다시 train/validation으로 쪼갬\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7F7kniptdJH",
        "outputId": "1a922893-3d00-44b8-cc64-6fc65dc366b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "'''"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprint(X_train.shape)\\nprint(y_train.shape)\\nprint(X_val.shape)\\nprint(y_val.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpP84KLVZQwY"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyE6pbZfLHw",
        "outputId": "dd2ad530-3957-4157-c27b-513f7afcb05b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "label_idx={}\n",
        "label_idx['ham']=0\n",
        "label_idx['spam']=1\n",
        "label_idx"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ham': 0, 'spam': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Vn2ge6ZVAY"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense, Input, Flatten, Concatenate,MaxPooling1D"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHpCFOa6ZXFV"
      },
      "source": [
        "filter_sizes = [3,4,5]\n",
        "num_filters = 100\n",
        "drop = 0.5"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_P_cxbsZZOI",
        "outputId": "daa83fed-b234-4dc3-8b0a-87516578076e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_input = Input(shape = (max_len,))\n",
        "#하나의 단어 임베딩은 훈련시키고, 나머지는 고정\n",
        "z = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n",
        "                      input_length=max_len, trainable=False)(model_input)\n",
        "z1 = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n",
        "                      input_length=max_len, trainable=True)(model_input)\n",
        "\n",
        "conv_blocks = []\n",
        "\n",
        "#크기 3,4,5인 필터를 만듦/ 단어 임베딩을 copy했기 때문에 3개가 아니라 6개 \n",
        "conv1 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 3,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z)\n",
        "conv2 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 4,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z)\n",
        "conv3 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 5,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z)\n",
        "\n",
        "conv4 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 3,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z1)\n",
        "conv5 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 4,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z1)\n",
        "conv6 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 5,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z1)\n",
        "\n",
        "#maxpooling 적용\n",
        "maxpooling1 = MaxPooling1D(max_len-3+1,1)(conv1)\n",
        "maxpooling2 = MaxPooling1D(max_len-4+1,1)(conv2)\n",
        "maxpooling3 = MaxPooling1D(max_len-5+1,1)(conv3)\n",
        "maxpooling4 = MaxPooling1D(max_len-3+1,1)(conv4)\n",
        "maxpooling5 = MaxPooling1D(max_len-4+1,1)(conv5)\n",
        "maxpooling6 = MaxPooling1D(max_len-5+1,1)(conv6)\n",
        "\n",
        "#6개의 maxpooling 값을 concatenate함\n",
        "z = Concatenate(axis=1)([maxpooling1,maxpooling2,maxpooling3,maxpooling4,maxpooling5,maxpooling6]) \n",
        "flatten = Flatten()(z)\n",
        "\n",
        "\n",
        "dropout = Dropout(drop)(flatten)\n",
        "#sigmoid함수에 넣어서 함수값 출력\n",
        "model_output = Dense(1, activation='sigmoid')(dropout)\n",
        "\n",
        "model = Model(model_input, model_output)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 73)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 73, 100)      625400      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 73, 100)      625400      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 71, 100)      30100       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 70, 100)      40100       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 69, 100)      50100       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 71, 100)      30100       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 70, 100)      40100       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 69, 100)      50100       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 1, 100)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 1, 100)       0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 1, 100)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 1, 100)       0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 1, 100)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 1, 100)       0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 100)       0           max_pooling1d[0][0]              \n",
            "                                                                 max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "                                                                 max_pooling1d_3[0][0]            \n",
            "                                                                 max_pooling1d_4[0][0]            \n",
            "                                                                 max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 600)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 600)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            601         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,492,001\n",
            "Trainable params: 866,601\n",
            "Non-trainable params: 625,400\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp5UqKKfDM3B",
        "outputId": "c5634a41-26b5-47d7-b7df-ef611fd30dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "'''\n",
        "model_input = Input(shape = (max_len,))\n",
        "z = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n",
        "                      input_length=max_len, trainable=False)(model_input)\n",
        "z1 = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n",
        "                      input_length=max_len, trainable=True)(model_input)\n",
        "\n",
        "conv_blocks = []\n",
        "\n",
        "conv1 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 3,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z)\n",
        "conv2 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 4,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z)\n",
        "conv3 = Conv1D(filters = num_filters,\n",
        "                         kernel_size = 5,\n",
        "                         padding = \"valid\",\n",
        "                         activation = \"relu\",\n",
        "                         strides = 1)(z)\n",
        "\n",
        "\n",
        "maxpooling1 = MaxPooling1D(max_len-3+1,1)(conv1)\n",
        "maxpooling2 = MaxPooling1D(max_len-4+1,1)(conv2)\n",
        "maxpooling3 = MaxPooling1D(max_len-5+1,1)(conv3)\n",
        "\n",
        "z = Concatenate(axis=1)([maxpooling1,maxpooling2,maxpooling3]) \n",
        "flatten = Flatten()(z)\n",
        "\n",
        "\n",
        "dropout = Dropout(drop)(flatten)\n",
        "model_output = Dense(1, activation='sigmoid')(dropout)\n",
        "\n",
        "model = Model(model_input, model_output)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "'''"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmodel_input = Input(shape = (max_len,))\\nz = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\\n                      input_length=max_len, trainable=False)(model_input)\\nz1 = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\\n                      input_length=max_len, trainable=True)(model_input)\\n\\nconv_blocks = []\\n\\nconv1 = Conv1D(filters = num_filters,\\n                         kernel_size = 3,\\n                         padding = \"valid\",\\n                         activation = \"relu\",\\n                         strides = 1)(z)\\nconv2 = Conv1D(filters = num_filters,\\n                         kernel_size = 4,\\n                         padding = \"valid\",\\n                         activation = \"relu\",\\n                         strides = 1)(z)\\nconv3 = Conv1D(filters = num_filters,\\n                         kernel_size = 5,\\n                         padding = \"valid\",\\n                         activation = \"relu\",\\n                         strides = 1)(z)\\n\\n\\nmaxpooling1 = MaxPooling1D(max_len-3+1,1)(conv1)\\nmaxpooling2 = MaxPooling1D(max_len-4+1,1)(conv2)\\nmaxpooling3 = MaxPooling1D(max_len-5+1,1)(conv3)\\n\\nz = Concatenate(axis=1)([maxpooling1,maxpooling2,maxpooling3]) \\nflatten = Flatten()(z)\\n\\n\\ndropout = Dropout(drop)(flatten)\\nmodel_output = Dense(1, activation=\\'sigmoid\\')(dropout)\\n\\nmodel = Model(model_input, model_output)\\n\\nmodel.compile(loss=\\'binary_crossentropy\\',\\n              optimizer=\\'rmsprop\\',\\n              metrics=[\\'accuracy\\'])\\n\\nmodel.summary()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdgkAXY0fC-d",
        "outputId": "2c688a7b-3abc-46e4-817b-05b380194196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.1680 - accuracy: 0.9368\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0555 - accuracy: 0.9830\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0327 - accuracy: 0.9904\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0169 - accuracy: 0.9958\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0103 - accuracy: 0.9972\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9988\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 0.9992\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9988\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gvfi2oBtFEg"
      },
      "source": [
        "### 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W10Sa7IAiDJV"
      },
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "#y_predicted = y_predicted.argmax(axis=-1) # 예측된 정수 시퀀스로 변환\n",
        "y_pred=[]\n",
        "for i in y_predicted:\n",
        "  y_exp = (1 if i > 0.5 else 0) #1\n",
        "  y_pred.append(y_exp)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3D6DOEKuBcv"
      },
      "source": [
        "#y_predicted = idx_encode.inverse_transform(y_predicted) # 정수 시퀀스를 레이블에 해당하는 텍스트 시퀀스로 변환\n",
        "#y_test = idx_encode.inverse_transform(y_test) # 정수 시퀀스를 레이블에 해당하는 텍스트 시퀀스로 변환"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apwl_hN00ZW9",
        "outputId": "a548c66e-97ec-4d0b-a2fe-e0c067289b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "#plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "#plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuo1qMfSuDwM",
        "outputId": "525ca733-dce4-42a9-c005-f3738739b306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "print('accuracy: ', accuracy_score(y_test,y_pred)) #0.96\n",
        "print(\"Recall\", recall_score(y_test, y_pred)) #0.72\n",
        "print(\"F1 score\", f1_score(y_test, y_pred)) #0.83"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.9802867383512545\n",
            "Recall 0.88\n",
            "F1 score 0.9230769230769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_mDHmK-wdCg",
        "outputId": "7c3e3dab-3ba9-47ae-b8f5-58865989f8dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[481,   2],\n",
              "       [  9,  66]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}